{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Dependency Risk Profiler","text":""},{"location":"#overview","title":"Overview","text":"<p>Dependency Risk Profiler is a comprehensive tool for evaluating the health and risk of your project's dependencies beyond traditional vulnerability scanning. It analyzes multiple risk factors such as maintainer activity, update frequency, community health, license compliance, and known vulnerabilities to provide a holistic risk assessment.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Multi-language Support: Analyze dependencies in Python, JavaScript/Node.js, and Go projects</li> <li>Comprehensive Risk Scoring: Assess risk based on multiple factors, not just vulnerabilities</li> <li>Supply Chain Insights: Understand your dependency graph and identify potential risks</li> <li>Vulnerability Detection: Identify security vulnerabilities in your dependencies</li> <li>License Compliance: Check for license compatibility and compliance issues</li> <li>Community Health Metrics: Evaluate the health of dependency maintainer communities</li> <li>Trend Analysis: Track risk scores over time to identify patterns</li> <li>CLI &amp; API Access: Use as a command-line tool or integrate into your own applications</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install dependency-risk-profiler\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Analyze a project with a single command:</p> <pre><code>dependency-risk-profiler analyze path/to/project\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<p>Explore our documentation for detailed guides on:</p> <ul> <li>Getting Started</li> <li>Installation Options</li> <li>Basic Usage</li> <li>Advanced Configuration</li> <li>Understanding Risk Scores</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<p>We welcome contributions! See our Contributing Guide for details on how to get involved.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License - see the LICENSE file for details.</p>"},{"location":"CHANGELOG/","title":"Changelog","text":"<p>All notable changes to the Dependency Risk Profiler will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"CHANGELOG/#030-2025-04-18","title":"[0.3.0] - 2025-04-18","text":""},{"location":"CHANGELOG/#added","title":"Added","text":"<ul> <li>Directory scanning feature to analyze all manifest files in a directory with a single command</li> <li>Support for recursive scanning of subdirectories with <code>--recursive</code> flag</li> <li>Automatic ecosystem detection for all manifest files</li> <li>Overall summary of risk scores across all scanned files</li> <li>Timeout control for improved performance with large projects</li> <li>New <code>--timeout</code> option to set the maximum analysis time per file</li> <li>Default timeout of 120 seconds per file</li> <li>Timeout error handling with helpful messages</li> <li>Enhanced summary report with categorized failed files</li> <li>Helpful tips for resolving analysis failures</li> <li>Comprehensive test suite following TESTING_STANDARDS.md:</li> <li>Hypothesis tests for behavior validation</li> <li>Regression tests for known fail states</li> <li>Benchmark tests with SLA enforcement</li> <li>Fuzzing tests for edge case discovery</li> <li>Structured logging tests for agent feedback</li> </ul>"},{"location":"CHANGELOG/#changed","title":"Changed","text":"<ul> <li>Added pytest-benchmark and numpy for performance testing</li> <li>Updated docstrings and error handling in tests</li> <li>Improved mocking and test coverage</li> <li>Refactored test code for testability and maintainability</li> <li>Fixed timezone handling in datetime comparisons</li> <li>Implemented direct testing patterns to avoid complex mocking</li> <li>Added proper benchmark test markers in pyproject.toml</li> <li>Fixed parameter mismatch in RiskScorer configuration</li> <li>Added proper HTTP session closure to prevent resource leaks</li> </ul>"},{"location":"CHANGELOG/#security","title":"Security","text":"<ul> <li>Updated all dependencies to latest secure versions:</li> <li>pytest: Updated to &gt;=8.4.0</li> <li>pytest-cov: Updated to &gt;=4.2.0</li> <li>black: Updated to &gt;=24.4.0</li> <li>mypy: Updated to &gt;=1.9.0</li> <li>numpy: Updated to &gt;=2.2.4</li> </ul>"},{"location":"CHANGELOG/#fixed","title":"Fixed","text":"<ul> <li>Changed dependencies to ensure wider compatibility:</li> <li>Downgraded networkx requirement from &gt;=3.3 to &gt;=2.8.8 for better compatibility</li> <li>Adjusted matplotlib requirement from &gt;=3.8.3 to &gt;=3.7.0</li> <li>Changed pytest requirement from &gt;=8.4.0 to &gt;=7.4.0 for CI compatibility</li> <li>Fixed security vulnerabilities in example files:</li> <li>Django: Updated to 5.1.8 (fixes multiple CVEs)</li> <li>Express: Updated to 4.18.2</li> <li>Lodash: Updated to 4.17.21</li> <li>React: Updated to 18.2.0</li> <li>Axios: Updated to 1.6.5</li> <li>Go dependencies upgraded to latest versions</li> <li>Updated package metadata with correct author information</li> </ul>"},{"location":"CHANGELOG/#020-2025-04-16","title":"[0.2.0] - 2025-04-16","text":""},{"location":"CHANGELOG/#added_1","title":"Added","text":"<ul> <li>License and compliance analysis for dependencies</li> <li>Community health metrics (stars, forks, contributors)</li> <li>Transitive dependency analysis for deeper supply chain insights</li> <li>Security posture analysis (security policies, branch protection, signed commits)</li> <li>Aggregation of vulnerability data from multiple sources (OSV, NVD, GitHub Advisory)</li> <li>Historical trends analysis with visualization capabilities</li> <li>Supply chain visualization with interactive dependency graphs</li> <li>Secure code signing and release management functionality</li> <li>Support for Pipfile.lock in addition to requirements.txt for Python projects</li> <li>TOML file parser for analyzing pyproject.toml (Poetry, PEP 621) and Cargo.toml (Rust) dependencies</li> </ul>"},{"location":"CHANGELOG/#security_1","title":"Security","text":"<ul> <li>Updated dependency requirements to address security vulnerabilities:</li> <li>requests: Updated to &gt;=2.32.2 (fixes CVE-2024-35195)</li> <li>urllib3: Updated to &gt;=2.2.2 (fixes CVE-2024-37891)</li> <li>jinja2: Updated to &gt;=3.1.5 (fixes CVE-2024-56201)</li> <li>certifi: Updated to &gt;=2024.7.4 (fixes CVE-2024-39689)</li> <li>werkzeug: Updated to &gt;=3.0.6 (fixes CVE-2024-49766, CVE-2024-49767)</li> <li>cryptography: Updated to &gt;=42.0.0 (fixes CVE-2023-50782 and others)</li> <li>pyyaml: Updated to &gt;=6.0.1 (addresses potential vulnerabilities)</li> <li>pygments: Added &gt;=2.16.1 (fixes CVE-2023-41337)</li> <li>pillow: Added &gt;=10.2.0 (fixes CVE-2023-50447, CVE-2024-35219)</li> <li>Updated development dependencies to secure versions:</li> <li>pytest: Updated to &gt;=7.4.4</li> <li>pytest-cov: Updated to &gt;=4.1.0</li> <li>black: Updated to &gt;=24.2.0</li> <li>isort: Updated to &gt;=5.13.2</li> <li>flake8: Updated to &gt;=7.0.0</li> <li>mypy: Updated to &gt;=1.6.0</li> <li>Added responses &gt;=0.25.0 for HTTP mocking in tests</li> </ul>"},{"location":"CHANGELOG/#changed_1","title":"Changed","text":"<ul> <li>Improved code organization and documentation</li> <li>Enhanced error handling and logging</li> <li>Fixed linting issues and code style inconsistencies</li> <li>Updated installation scripts for better cross-platform compatibility</li> </ul>"},{"location":"CHANGELOG/#010-2025-04-15","title":"[0.1.0] - 2025-04-15","text":""},{"location":"CHANGELOG/#added_2","title":"Added","text":"<ul> <li>Initial release of the Dependency Risk Profiler</li> <li>Support for analyzing Node.js (package-lock.json), Python (requirements.txt), and Go (go.mod) dependencies</li> <li>Risk scoring based on multiple factors:</li> <li>Update recency (staleness)</li> <li>Number of maintainers</li> <li>Deprecation status</li> <li>Known vulnerabilities</li> <li>Version differences</li> <li>Health indicators (tests, CI, contribution guidelines)</li> <li>Color-coded terminal output</li> <li>JSON output option</li> <li>Customizable risk scoring weights</li> <li>Basic test suite</li> </ul>"},{"location":"CONTRIBUTING/","title":"Contributing to Dependency Risk Profiler","text":"<p>Thank you for your interest in contributing to the Dependency Risk Profiler! This document outlines the process for contributing to this project.</p>"},{"location":"CONTRIBUTING/#code-of-conduct","title":"Code of Conduct","text":"<p>By participating in this project, you agree to abide by our code of conduct: be respectful, considerate, and collaborative.</p>"},{"location":"CONTRIBUTING/#how-to-contribute","title":"How to Contribute","text":""},{"location":"CONTRIBUTING/#reporting-bugs","title":"Reporting Bugs","text":"<p>If you find a bug, please create a GitHub issue with the following information:</p> <ol> <li>Clear, descriptive title</li> <li>Steps to reproduce the bug</li> <li>Expected behavior</li> <li>Actual behavior</li> <li>Your environment (OS, Python version, etc.)</li> <li>Any relevant logs or screenshots</li> </ol>"},{"location":"CONTRIBUTING/#suggesting-enhancements","title":"Suggesting Enhancements","text":"<p>We welcome suggestions for new features or improvements. Please create a GitHub issue with:</p> <ol> <li>Clear, descriptive title</li> <li>Detailed description of the proposed enhancement</li> <li>Use cases and benefits</li> <li>Any implementation ideas you have</li> </ol>"},{"location":"CONTRIBUTING/#pull-requests","title":"Pull Requests","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch (<code>git checkout -b feature/amazing-feature</code>)</li> <li>Make your changes</li> <li>Run tests to ensure they pass</li> <li>Commit your changes (<code>git commit -m 'Add amazing feature'</code>)</li> <li>Push to the branch (<code>git push origin feature/amazing-feature</code>)</li> <li>Open a Pull Request</li> </ol>"},{"location":"CONTRIBUTING/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<ul> <li>Follow the code style guidelines specified in CLAUDE.md</li> <li>Include tests for new features or bug fixes</li> <li>Update documentation as needed</li> <li>Keep pull requests focused on a single topic</li> <li>Reference related issues in your PR description</li> </ul>"},{"location":"CONTRIBUTING/#development-process","title":"Development Process","text":""},{"location":"CONTRIBUTING/#setting-up-your-development-environment","title":"Setting Up Your Development Environment","text":"<pre><code># Clone your fork\ngit clone https://github.com/YOUR_USERNAME/dependency-risk-profiler.git\ncd dependency-risk-profiler\n\n# Create a virtual environment\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Install development dependencies\npip install -e \".[dev]\"\n\n# Set up pre-commit hooks\npre-commit install\n</code></pre>"},{"location":"CONTRIBUTING/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\npytest\n\n# Run specific tests\npytest tests/test_parsers.py\n\n# Run tests with coverage\npytest --cov=src\n</code></pre>"},{"location":"CONTRIBUTING/#code-style","title":"Code Style","text":"<p>We use the following tools to maintain code quality:</p> <ul> <li>Black: Code formatting</li> <li>isort: Import sorting</li> <li>flake8: Linting</li> <li>mypy: Type checking</li> </ul> <p>Before submitting a PR, please run these tools:</p> <pre><code>black .\nisort .\nflake8\nmypy .\n</code></pre>"},{"location":"CONTRIBUTING/#adding-support-for-new-package-ecosystems","title":"Adding Support for New Package Ecosystems","text":"<p>If you want to add support for a new package ecosystem, you'll need to:</p> <ol> <li>Create a new parser module in <code>src/dependency_risk_profiler/parsers/</code></li> <li>Create a new analyzer module in <code>src/dependency_risk_profiler/analyzers/</code></li> <li>Update the factory methods in <code>base.py</code> to include your new modules</li> <li>Add tests for your new parser and analyzer</li> <li>Update documentation to reflect the new supported ecosystem</li> </ol>"},{"location":"CONTRIBUTING/#documentation","title":"Documentation","text":"<p>Please update documentation for any changes that affect user experience or public APIs. This includes:</p> <ul> <li>README.md</li> <li>Code docstrings</li> <li>CLI help text</li> </ul>"},{"location":"CONTRIBUTING/#releasing","title":"Releasing","text":"<p>Project maintainers will handle releases, following semantic versioning:</p> <ul> <li>MAJOR: Incompatible API changes (2.0.0)</li> <li>MINOR: New functionality, backwards compatible (1.1.0)</li> <li>PATCH: Bug fixes, backwards compatible (1.0.1)</li> </ul>"},{"location":"CONTRIBUTING/#questions","title":"Questions?","text":"<p>If you have any questions about contributing, feel free to open an issue asking for clarification.</p>"},{"location":"INFORMATION_SOURCES/","title":"Dependency Risk Profiler: Information Sources","text":"<p>This document details the various information sources and methodologies used by the Dependency Risk Profiler to collect dependency metadata for risk assessment.</p>"},{"location":"INFORMATION_SOURCES/#package-registry-apis","title":"Package Registry APIs","text":""},{"location":"INFORMATION_SOURCES/#nodejs-npm","title":"Node.js (npm)","text":"<p>The tool retrieves package information from the npm registry's public API:</p> <ul> <li>Endpoint: <code>https://registry.npmjs.org/{package-name}</code></li> <li>Information Retrieved:</li> <li>Latest version</li> <li>Deprecation status</li> <li>Repository URL</li> <li>Release dates</li> <li>Maintainer information (partial)</li> </ul> <p>Example API response structure: <pre><code>{\n  \"name\": \"package-name\",\n  \"version\": \"1.2.3\",\n  \"deprecated\": false,\n  \"repository\": {\n    \"type\": \"git\", \n    \"url\": \"https://github.com/org/repo\"\n  },\n  \"time\": {\n    \"1.0.0\": \"2023-01-01T00:00:00.000Z\",\n    \"1.2.3\": \"2023-04-15T00:00:00.000Z\"\n  },\n  \"maintainers\": [\n    {\"name\": \"user1\", \"email\": \"user1@example.com\"}\n  ]\n}\n</code></pre></p>"},{"location":"INFORMATION_SOURCES/#python-pypi","title":"Python (PyPI)","text":"<p>The tool uses PyPI's JSON API to retrieve package metadata:</p> <ul> <li>Endpoint: <code>https://pypi.org/pypi/{package-name}/json</code></li> <li>Information Retrieved:</li> <li>Latest version</li> <li>Project URLs (including repository)</li> <li>Description (checked for deprecation indicators)</li> <li>Release history</li> </ul> <p>Example API response structure: <pre><code>{\n  \"info\": {\n    \"name\": \"package-name\",\n    \"version\": \"1.2.3\",\n    \"description\": \"A useful package\",\n    \"project_urls\": {\n      \"Source\": \"https://github.com/org/repo\",\n      \"Documentation\": \"https://docs.example.com\"\n    }\n  },\n  \"releases\": {\n    \"1.0.0\": [{\"upload_time\": \"2023-01-01T00:00:00\"}],\n    \"1.2.3\": [{\"upload_time\": \"2023-04-15T00:00:00\"}]\n  }\n}\n</code></pre></p>"},{"location":"INFORMATION_SOURCES/#go-packages","title":"Go Packages","text":"<p>For Go packages, information is extracted from pkg.go.dev:</p> <ul> <li>Method: HTML scraping of <code>https://pkg.go.dev/{import-path}</code></li> <li>Information Retrieved:</li> <li>Latest version (from version indicator)</li> <li>Repository URL (inferred from import path)</li> </ul>"},{"location":"INFORMATION_SOURCES/#repository-analysis","title":"Repository Analysis","text":"<p>When a repository URL is available (typically from GitHub, GitLab, or Bitbucket), the tool performs additional analysis:</p>"},{"location":"INFORMATION_SOURCES/#repository-cloning","title":"Repository Cloning","text":"<ul> <li>The tool creates a temporary clone of the repository using:   <pre><code>git clone --depth 1 {repository-url} {temp-directory}\n</code></pre></li> <li>This shallow clone helps minimize bandwidth and storage requirements while still providing access to the latest code.</li> </ul>"},{"location":"INFORMATION_SOURCES/#last-update-analysis","title":"Last Update Analysis","text":"<ul> <li>Command: <code>git log -1 --format=%cd --date=iso</code></li> <li>Purpose: Determines when the package was last updated.</li> <li>Limitation: A shallow clone only sees recent commit history.</li> </ul>"},{"location":"INFORMATION_SOURCES/#contributor-analysis","title":"Contributor Analysis","text":"<ul> <li>Command: <code>git shortlog -s -n --all</code></li> <li>Purpose: Counts unique contributors to estimate maintainer diversity.</li> <li>Limitation: Shallow clones limit the accuracy of this count.</li> </ul>"},{"location":"INFORMATION_SOURCES/#health-indicators-analysis","title":"Health Indicators Analysis","text":"<p>The tool scans the repository structure for indicators of project health:</p> <ol> <li>Tests:</li> <li>Looks for directories named <code>test</code>, <code>tests</code>, <code>spec</code>, or <code>specs</code></li> <li> <p>Looks for files matching patterns like <code>*_test.py</code>, <code>*.test.js</code>, etc.</p> </li> <li> <p>CI Configuration:</p> </li> <li> <p>Checks for CI configuration files:</p> <ul> <li><code>.travis.yml</code></li> <li><code>.github/workflows/*</code></li> <li><code>.circleci/config.yml</code></li> <li><code>.gitlab-ci.yml</code></li> <li><code>azure-pipelines.yml</code></li> <li><code>Jenkinsfile</code></li> <li>etc.</li> </ul> </li> <li> <p>Contribution Guidelines:</p> </li> <li>Looks for files like:<ul> <li><code>CONTRIBUTING.md</code></li> <li><code>.github/CONTRIBUTING.md</code></li> <li><code>DEVELOPMENT.md</code></li> <li>etc.</li> </ul> </li> </ol>"},{"location":"INFORMATION_SOURCES/#security-information","title":"Security Information","text":"<p>The current implementation uses a simplified approach to identify potential security issues:</p> <ul> <li>Package Documentation: Scans package descriptions and documentation for keywords related to security issues (e.g., \"vulnerability\", \"security\", \"CVE\").</li> <li>Simple Pattern Matching: Checks for patterns like \"CVE-####-####\" that might indicate known vulnerabilities.</li> </ul> <p>Note: This is a basic approach and not as comprehensive as dedicated security scanners. Future versions could integrate with: - OSV (Open Source Vulnerabilities) database - GitHub Advisory Database - NPM Security Advisories - NVD (National Vulnerability Database)</p>"},{"location":"INFORMATION_SOURCES/#version-comparison","title":"Version Comparison","text":"<p>The tool compares installed and latest versions using the following approach:</p> <ol> <li>Version Parsing: Uses the Python <code>packaging.version</code> module to parse semantic versions.</li> <li>Version Difference Analysis:</li> <li>Compares major, minor, and patch components</li> <li>Higher weight given to major version differences</li> <li>Special handling for pre-release versions and non-standard versioning schemes</li> </ol>"},{"location":"INFORMATION_SOURCES/#data-processing-approach","title":"Data Processing Approach","text":"<p>All data collection follows these principles:</p> <ol> <li>Public Information Only: All information is gathered from publicly available sources, without requiring API keys or authentication.</li> <li>Network Resilience: The tool handles network failures gracefully and falls back to partial information when complete data is unavailable.</li> <li>Local Processing: Analysis is performed locally without sending dependency information to external services.</li> <li>Temporary Storage: Repository clones and other temporary data are stored in temporary directories and cleaned up after use.</li> </ol>"},{"location":"INFORMATION_SOURCES/#privacy-and-security-considerations","title":"Privacy and Security Considerations","text":"<ul> <li>No dependency information is transmitted to external servers beyond the necessary API calls to public registries.</li> <li>The tool does not execute any code from the dependencies it analyzes.</li> <li>Repository credentials are never stored or used.</li> <li>All network requests use proper User-Agent identification.</li> </ul>"},{"location":"INFORMATION_SOURCES/#limitations","title":"Limitations","text":"<ol> <li>Rate Limiting: Public APIs may impose rate limits that can restrict the tool's ability to analyze large numbers of dependencies in rapid succession.</li> <li>Data Availability: Not all packages provide complete information through public APIs.</li> <li>Network Dependence: The tool requires internet access to retrieve up-to-date information.</li> <li>Shallow Analysis: Due to performance considerations, repository analysis uses shallow clones which may miss some historical context.</li> </ol> <p>This documentation describes the information sources as of version 0.1.0 of the Dependency Risk Profiler.</p>"},{"location":"MIGRATION_SUMMARY/","title":"Migration Summary: Modernizing the Dependency Risk Profiler","text":""},{"location":"MIGRATION_SUMMARY/#overview","title":"Overview","text":"<p>This document summarizes the improvements made to modernize the Dependency Risk Profiler project structure and configuration. The primary goal was to implement all improvements listed in <code>Improvements.md</code>, focusing on moving to modern Python packaging standards.</p>"},{"location":"MIGRATION_SUMMARY/#completed-improvements","title":"Completed Improvements","text":""},{"location":"MIGRATION_SUMMARY/#1-test-directory-reorganization","title":"1. Test Directory Reorganization","text":"<ul> <li>Consolidated all tests, test_projects, and test_dirs into a unified testing structure:</li> <li>Created a consistent hierarchy with <code>testing/</code> as the main directory</li> <li>Organized tests into logical categories (unit, integration, fixtures, manifests, projects)</li> <li>Added symlink from <code>tests</code> to <code>testing</code> for backward compatibility</li> <li>Updated import paths and test references across the codebase</li> <li>Fixed CI/CD configurations to use the new path structure</li> <li>Added README files to document the purpose of each test directory</li> <li>Ensured all 171 tests pass with the new structure</li> </ul>"},{"location":"MIGRATION_SUMMARY/#2-configuration-consolidation","title":"2. Configuration Consolidation","text":"<ul> <li>Migrated all configuration from legacy files to <code>pyproject.toml</code>:</li> <li>Moved settings from <code>setup.py</code>, <code>setup.cfg</code>, <code>MANIFEST.in</code>, <code>mypy.ini</code>, etc.</li> <li>Added proper build system configuration</li> <li>Added all metadata including dependencies, classifiers, and URLs</li> <li>Added development dependencies and optional dependency groups</li> </ul>"},{"location":"MIGRATION_SUMMARY/#2-pre-commit-hooks-enhancement","title":"2. Pre-commit Hooks Enhancement","text":"<ul> <li>Updated <code>.pre-commit-config.yaml</code> with additional hooks:</li> <li>Added flake8, mypy, and bandit security scanning</li> <li>Configured appropriate exclusions for test directories</li> <li>Set up proper default settings to ensure code quality</li> </ul>"},{"location":"MIGRATION_SUMMARY/#3-github-actions-workflow-creation","title":"3. GitHub Actions Workflow Creation","text":"<ul> <li>Created <code>release.yml</code> workflow for automatic deployment</li> <li>Configured to trigger on version tags (v..*)</li> <li>Set up automatic changelog generation</li> <li>Added PyPI publishing</li> </ul>"},{"location":"MIGRATION_SUMMARY/#4-installation-script-improvement","title":"4. Installation Script Improvement","text":"<ul> <li>Rewrote <code>install.py</code> with modern options:</li> <li>Added both interactive and command-line modes</li> <li>Improved virtual environment handling</li> <li>Added pre-commit hook installation</li> <li>Enhanced cross-platform support</li> </ul>"},{"location":"MIGRATION_SUMMARY/#5-documentation-updates","title":"5. Documentation Updates","text":"<ul> <li>Added badges to README.md (CI, coverage, Python version, license)</li> <li>Added CI/CD documentation section</li> <li>Documented GitHub Actions workflows</li> <li>Updated development instructions</li> <li>Added comprehensive usage examples</li> </ul>"},{"location":"MIGRATION_SUMMARY/#6-legacy-file-cleanup","title":"6. Legacy File Cleanup","text":"<ul> <li>Created <code>cleanup_legacy.py</code> script to safely remove obsolete files</li> <li>Added backup functionality to prevent data loss</li> <li>Made the script interactive with confirmation prompts</li> <li>Added support for non-interactive environments with <code>--force</code> flag</li> </ul>"},{"location":"MIGRATION_SUMMARY/#7-test-updates","title":"7. Test Updates","text":"<ul> <li>Updated tests to work with the new configuration structure</li> <li>Specifically modified the CI config tests and mypy tests to use <code>pyproject.toml</code></li> <li>Fixed failing tests with proper configuration</li> </ul>"},{"location":"MIGRATION_SUMMARY/#verification","title":"Verification","text":"<ul> <li>Confirmed package can still be installed: \u2713</li> <li>Verified all tests pass: \u2713</li> <li>Confirmed CLI functionality: \u2713</li> <li>Validated CI/CD workflow: \u2713</li> </ul>"},{"location":"MIGRATION_SUMMARY/#legacy-files-removed","title":"Legacy Files Removed","text":"<ul> <li>setup.py</li> <li>setup.cfg</li> <li>MANIFEST.in</li> <li>mypy.ini</li> <li>.flake8</li> </ul>"},{"location":"MIGRATION_SUMMARY/#files-createdupdated","title":"Files Created/Updated","text":"<ul> <li>pyproject.toml (updated)</li> <li>.github/workflows/release.yml (created)</li> <li>.github/workflows/ci.yml (updated)</li> <li>.flake8 (created)</li> <li>install.py (rewritten)</li> <li>cleanup_legacy.py (created)</li> <li>README.md (updated)</li> <li>testing/ (created with subdirectories)</li> <li>testing/README.md (created)</li> <li>testing/unit/ (moved from tests/)</li> <li>testing/integration/ (moved from tests/)</li> <li>testing/fixtures/ (created)</li> <li>testing/manifests/ (moved from test_dirs/)</li> <li>testing/projects/ (moved from test-projects/)</li> <li>src/dependency_risk_profiler/secure_release/github_actions_ci_cd.yaml (updated)</li> </ul>"},{"location":"MIGRATION_SUMMARY/#future-recommendations","title":"Future Recommendations","text":"<ol> <li>Create a release to test the new release workflow</li> <li>Consider adding more automation for dependency updates</li> <li>Improve test documentation with examples for each test category</li> <li>Add more integration tests to increase coverage</li> <li>Implement automatic enforcement of code quality standards in CI pipeline</li> </ol>"},{"location":"MIGRATION_SUMMARY/#conclusion","title":"Conclusion","text":"<p>The project now follows modern Python packaging standards and best practices. All configuration is centralized in <code>pyproject.toml</code>, making it easier to maintain and update. The removal of legacy files has simplified the project structure, and the addition of proper CI/CD workflows has improved the development and release process.</p>"},{"location":"SCORING/","title":"Dependency Risk Profiler: Scoring Methodology","text":"<p>This document explains how the Dependency Risk Profiler calculates risk scores for dependencies and the sources of information used in the analysis.</p>"},{"location":"SCORING/#overview","title":"Overview","text":"<p>The Dependency Risk Profiler evaluates dependencies across multiple dimensions to provide a comprehensive risk assessment beyond traditional vulnerability scanning. Each dependency receives a risk score on a scale of 0.0 to 5.0, which is then categorized into risk levels (LOW, MEDIUM, HIGH, or CRITICAL).</p>"},{"location":"SCORING/#data-collection-sources","title":"Data Collection Sources","text":"<p>The tool collects information from various sources to evaluate dependency health:</p>"},{"location":"SCORING/#1-package-registries","title":"1. Package Registries","text":"<ul> <li> <p>Node.js (npm): The tool queries the npm registry API (<code>https://registry.npmjs.org/[package-name]</code>) to retrieve package metadata including latest version, deprecation status, and repository information.</p> </li> <li> <p>Python (PyPI): The PyPI JSON API (<code>https://pypi.org/pypi/[package-name]/json</code>) provides package metadata including latest version, project URLs, and description text that might indicate deprecation.</p> </li> <li> <p>Go: For Go packages, we use the Go package site (<code>https://pkg.go.dev/[package]</code>) to extract latest version information.</p> </li> </ul>"},{"location":"SCORING/#2-source-code-repositories","title":"2. Source Code Repositories","text":"<p>When a repository URL is available, the tool clones the repository to analyze:</p> <ul> <li>Commit History: Using Git commands to extract the date of the most recent commit.</li> <li>Contributor Count: Using Git to count unique contributors via commit history.</li> <li>Health Indicators: Scanning the repository for the presence of:</li> <li>Test files/directories</li> <li>CI configuration files (.travis.yml, .github/workflows, etc.)</li> <li>Contribution guidelines (CONTRIBUTING.md, etc.)</li> </ul>"},{"location":"SCORING/#3-security-information","title":"3. Security Information","text":"<ul> <li>Vulnerability Databases: The tool queries multiple sources including OSV (Open Source Vulnerabilities), NVD (National Vulnerability Database), and GitHub Advisory Database.</li> <li>Security Indicators: Analysis of security policies, branch protection rules, signed commits, and dependency update tools.</li> <li>Security Documentation: Checking for presence of SECURITY.md and security-related documentation.</li> </ul>"},{"location":"SCORING/#risk-scoring-components","title":"Risk Scoring Components","text":"<p>The overall risk score is calculated from multiple components, each with configurable weights. The basic components include:</p>"},{"location":"SCORING/#1-staleness-score-default-weight-025","title":"1. Staleness Score (Default Weight: 0.25)","text":"<p>Measures how recently the dependency was updated:</p> Last Updated Score &lt; 1 month 0.0 1-3 months 0.25 3-6 months 0.5 6-12 months 0.75 &gt; 1 year 1.0"},{"location":"SCORING/#2-maintainer-score-default-weight-02","title":"2. Maintainer Score (Default Weight: 0.2)","text":"<p>Evaluates the number of active maintainers/contributors:</p> Maintainer Count Score 5+ 0.0 3-4 0.25 2 0.5 1 1.0 Unknown 0.5"},{"location":"SCORING/#3-deprecation-score-default-weight-03","title":"3. Deprecation Score (Default Weight: 0.3)","text":"<p>Indicates if the package is officially deprecated:</p> Status Score Deprecated 1.0 Not Deprecated 0.0"},{"location":"SCORING/#4-exploit-score-default-weight-05","title":"4. Exploit Score (Default Weight: 0.5)","text":"<p>Indicates if there are known security issues:</p> Status Score Known Exploits 1.0 No Known Exploits 0.0"},{"location":"SCORING/#5-version-difference-score-default-weight-015","title":"5. Version Difference Score (Default Weight: 0.15)","text":"<p>Measures how outdated the installed version is:</p> Version Difference Score Same Version 0.0 Patch Version (0.0.x) 0.25 Minor Version (0.x.0) 0.5 Major Version (x.0.0) 1.0 Unparseable 0.5"},{"location":"SCORING/#6-health-indicators-score-default-weight-01","title":"6. Health Indicators Score (Default Weight: 0.1)","text":"<p>Evaluates project health based on presence of tests, CI, and contribution guidelines:</p> Health Indicators Score All Present 0.0 None Present 1.0 Some Present Proportional (1 - ratio of present indicators) Unknown 0.5"},{"location":"SCORING/#enhanced-risk-components-v020","title":"Enhanced Risk Components (v0.2.0+)","text":"<p>These additional components are part of the enhanced risk model in version 0.2.0 and later:</p> <ol> <li>License Risk Score (Default Weight: 0.3)</li> </ol> <p>Evaluates the license type and compliance risk:</p> License Type Score Permissive (MIT, Apache, BSD) 0.0 Weak Copyleft (LGPL) 0.3 Strong Copyleft (GPL) 0.5 Non-standard 0.7 No License 1.0 <ol> <li>Community Health Score (Default Weight: 0.25)</li> </ol> <p>Evaluates community engagement metrics:</p> Community Factors Score Many stars, forks, and active PRs 0.0 Moderate activity 0.4 Low activity 0.7 Abandoned 1.0 <ol> <li>Security Policy Score (Default Weight: 0.35)</li> </ol> <p>Evaluates security practices in the repository:</p> Security Practices Score All security best practices 0.0 Some security practices 0.4 Few security practices 0.7 No security practices 1.0"},{"location":"SCORING/#calculation-process","title":"Calculation Process","text":"<ol> <li> <p>Individual Scoring: Each component is scored on a scale of 0.0 to 1.0.</p> </li> <li> <p>Weighted Average: The component scores are combined using a weighted average:    <pre><code>total_score = sum(component_score * weight for each component)\n</code></pre></p> </li> <li> <p>Normalization: The weighted average is normalized to the maximum score (default: 5.0):    <pre><code>normalized_score = (weighted_average / sum_of_weights) * max_score\n</code></pre></p> </li> <li> <p>Risk Level Assignment: The normalized score is mapped to a risk level:</p> </li> </ol> Score Range (% of max) Risk Level 0% - 25% (0.0 - 1.25) LOW 25% - 50% (1.25 - 2.5) MEDIUM 50% - 75% (2.5 - 3.75) HIGH 75% - 100% (3.75 - 5.0) CRITICAL <ol> <li>Risk Factors Identification: The tool identifies specific risk factors that contribute to the score, such as \"Single maintainer\", \"Not updated in X days\", or \"Known security issues\".</li> </ol>"},{"location":"SCORING/#customizing-the-scoring","title":"Customizing the Scoring","text":"<p>Users can customize the weights for each risk component via command-line arguments:</p> <pre><code>dependency-risk-profiler --manifest package-lock.json \\\n  --staleness-weight 0.3 \\\n  --maintainer-weight 0.2 \\\n  --deprecation-weight 0.3 \\\n  --exploit-weight 0.6 \\\n  --version-weight 0.2 \\\n  --health-weight 0.1\n</code></pre> <p>This allows organizations to adjust the scoring methodology to align with their specific risk tolerance and priorities.</p>"},{"location":"SCORING/#limitations-and-caveats","title":"Limitations and Caveats","text":"<ul> <li>The tool relies on publicly available information and anonymous access to package registries.</li> <li>Some metrics might be unavailable for certain packages, leading to the use of default scores.</li> <li>Repository analysis requires Git access and may be time-consuming for large repositories.</li> <li>Security vulnerability detection is basic and not a replacement for dedicated security scanning tools.</li> <li>Version parsing may not handle all non-standard versioning schemes correctly.</li> </ul>"},{"location":"SCORING/#future-enhancements","title":"Future Enhancements","text":"<ul> <li>Dependency usage analysis (how many projects depend on this package)</li> <li>More sophisticated version analysis (SemVer compliance, release frequency)</li> <li>Static code analysis metrics (code quality, test coverage)</li> </ul> <p>This document describes the risk scoring methodology as of version 0.2.0 of the Dependency Risk Profiler.</p>"},{"location":"basic-usage/","title":"Basic Usage","text":"<p>This guide covers the essential commands and workflows for using Dependency Risk Profiler.</p>"},{"location":"basic-usage/#command-line-interface","title":"Command Line Interface","text":"<p>Dependency Risk Profiler provides a comprehensive command-line interface (CLI) for analyzing projects.</p>"},{"location":"basic-usage/#available-commands","title":"Available Commands","text":"<pre><code># Show help and available commands\ndependency-risk-profiler --help\n\n# List supported ecosystems\ndependency-risk-profiler list-ecosystems\n\n# Analyze a project\ndependency-risk-profiler analyze path/to/project\n\n# Generate a sample configuration file\ndependency-risk-profiler generate-config --format toml\n</code></pre>"},{"location":"basic-usage/#analyzing-projects","title":"Analyzing Projects","text":"<p>The core functionality is provided by the <code>analyze</code> command:</p> <pre><code>dependency-risk-profiler analyze [OPTIONS] PATH\n</code></pre>"},{"location":"basic-usage/#common-options","title":"Common Options","text":"<ul> <li><code>--ecosystem TEXT</code>: Specify the ecosystem (python, nodejs, golang)</li> <li><code>--output-format [terminal|json]</code>: Output format (default: terminal)</li> <li><code>--config PATH</code>: Path to configuration file</li> <li><code>--output PATH</code>: Write output to file</li> <li><code>--verbose / --quiet</code>: Control log verbosity</li> </ul>"},{"location":"basic-usage/#examples","title":"Examples","text":"<pre><code># Basic analysis with auto-detection\ndependency-risk-profiler analyze .\n\n# Specify ecosystem explicitly\ndependency-risk-profiler analyze --ecosystem python .\n\n# Output results as JSON\ndependency-risk-profiler analyze --output-format json .\n\n# Write results to a file\ndependency-risk-profiler analyze --output results.json .\n\n# Use a custom configuration\ndependency-risk-profiler analyze --config my-config.toml .\n\n# Analyze a specific manifest file\ndependency-risk-profiler analyze requirements.txt\n</code></pre>"},{"location":"basic-usage/#analyzing-multiple-projects","title":"Analyzing Multiple Projects","text":"<p>To analyze multiple projects or compare different dependency files:</p> <pre><code># Analyze all Python projects in a directory\ndependency-risk-profiler analyze --recursive .\n\n# Analyze specific files\ndependency-risk-profiler analyze package.json requirements.txt go.mod\n</code></pre>"},{"location":"basic-usage/#working-with-results","title":"Working with Results","text":"<p>The analysis results can be used in various ways:</p>"},{"location":"basic-usage/#terminal-output","title":"Terminal Output","text":"<p>By default, results are displayed in a formatted terminal output:</p> <pre><code>Project Risk Analysis: my-project\n--------------------------------\nOverall Risk Score: 0.65 (MEDIUM)\n\nRisk Categories:\n  Vulnerability: 0.8 (HIGH)\n  Maintenance:   0.4 (LOW)\n  Community:     0.6 (MEDIUM)\n  License:       0.3 (LOW)\n\nHigh Risk Dependencies:\n  outdated-pkg (0.9.2): 3 critical vulnerabilities\n  abandoned-lib (1.0.0): No updates in 32 months\n</code></pre>"},{"location":"basic-usage/#json-output","title":"JSON Output","text":"<p>For programmatic use or further processing, use the JSON output format:</p> <pre><code>dependency-risk-profiler analyze --output-format json . &gt; results.json\n</code></pre> <p>This produces structured data that can be processed by other tools:</p> <pre><code>{\n  \"project\": \"my-project\",\n  \"timestamp\": \"2025-04-18T12:34:56Z\",\n  \"overall_risk\": {\n    \"score\": 0.65,\n    \"level\": \"MEDIUM\"\n  },\n  \"categories\": {\n    \"vulnerability\": {\"score\": 0.8, \"level\": \"HIGH\"},\n    \"maintenance\": {\"score\": 0.4, \"level\": \"LOW\"},\n    \"community\": {\"score\": 0.6, \"level\": \"MEDIUM\"},\n    \"license\": {\"score\": 0.3, \"level\": \"LOW\"}\n  },\n  \"dependencies\": [\n    {\n      \"name\": \"outdated-pkg\",\n      \"version\": \"0.9.2\",\n      \"risk_score\": 0.9,\n      \"risk_level\": \"HIGH\",\n      \"issues\": [\"3 critical vulnerabilities\"]\n    },\n    // More dependencies...\n  ]\n}\n</code></pre>"},{"location":"basic-usage/#visualizing-dependencies","title":"Visualizing Dependencies","text":"<p>To visualize dependency relationships and risks:</p> <pre><code>dependency-risk-profiler visualize-graph path/to/project\n\n# Output as different graph formats\ndependency-risk-profiler visualize-graph --format d3 path/to/project\ndependency-risk-profiler visualize-graph --format graphviz path/to/project\n</code></pre>"},{"location":"basic-usage/#tracking-trends-over-time","title":"Tracking Trends Over Time","text":"<p>To track how dependency risks change over time:</p> <pre><code># Generate initial trend data\ndependency-risk-profiler analyze --save-trends . \n\n# After some time/changes, update trends\ndependency-risk-profiler analyze --save-trends .\n\n# Visualize trends\ndependency-risk-profiler visualize-trends\n</code></pre>"},{"location":"basic-usage/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Configuration options</li> <li>Understand Risk Scoring methodologies</li> <li>Explore Information Sources used for risk assessment</li> </ul>"},{"location":"configuration/","title":"Configuration","text":"<p>Dependency Risk Profiler is highly configurable to adapt to different project needs and preferences. This guide covers the configuration options and how to customize the tool.</p>"},{"location":"configuration/#configuration-file","title":"Configuration File","text":"<p>The tool supports configuration through TOML or YAML files. You can generate a sample configuration file with:</p> <pre><code>dependency-risk-profiler generate-config --format toml &gt; dependency-risk-profiler.toml\n# or\ndependency-risk-profiler generate-config --format yaml &gt; dependency-risk-profiler.yml\n</code></pre>"},{"location":"configuration/#configuration-locations","title":"Configuration Locations","text":"<p>The tool searches for configuration in the following locations (in order of precedence):</p> <ol> <li>File specified with <code>--config</code> command-line option</li> <li><code>dependency-risk-profiler.toml</code> or <code>dependency-risk-profiler.yml</code> in the current directory</li> <li><code>.dependency-risk-profiler.toml</code> or <code>.dependency-risk-profiler.yml</code> in the current directory</li> <li><code>$XDG_CONFIG_HOME/dependency-risk-profiler/config.toml</code> or <code>config.yml</code></li> <li><code>~/.config/dependency-risk-profiler/config.toml</code> or <code>config.yml</code></li> </ol>"},{"location":"configuration/#configuration-options","title":"Configuration Options","text":"<p>Here's a sample configuration file with explanations:</p> <pre><code># Main configuration\n[general]\n# Default output format (terminal or json)\noutput_format = \"terminal\"\n\n# Cache settings\ncache_dir = \"~/.cache/dependency-risk-profiler\"\ncache_ttl_days = 7\n\n# API keys for various services\n[api_keys]\ngithub = \"\"  # GitHub personal access token\nsnyk = \"\"    # Snyk API key\nnvd = \"\"     # NVD API key\n\n# Risk scoring weights\n[scoring]\nvulnerability_weight = 0.4\nmaintenance_weight = 0.2\ncommunity_weight = 0.2\nlicense_weight = 0.2\n\n# Risk score thresholds\n[risk_levels]\nlow = 0.3    # Below this is low risk\nmedium = 0.7 # Below this is medium risk, above is high risk\n\n# Vulnerability scanning settings\n[vulnerability]\ninclude_experimental = false\nminimum_severity = \"medium\"  # none, low, medium, high, critical\nsources = [\"osv\", \"github\", \"nvd\"]\n\n# Maintenance assessment settings\n[maintenance]\nmax_age_days = 365  # Consider unmaintained after this many days\nactivity_window = 90  # Days to check for recent activity\n\n# Community health settings\n[community]\nmin_contributors = 3\nrequire_security_policy = true\n\n# License compliance settings\n[license]\nallowed_licenses = [\"MIT\", \"Apache-2.0\", \"BSD-3-Clause\"]\ndisallowed_licenses = [\"GPL-3.0\", \"AGPL-3.0\"]\n\n# Ecosystem-specific settings\n[ecosystems.python]\ntransitive_dependencies = true\nmax_depth = 5\n\n[ecosystems.nodejs]\ndevelopment_dependencies = false\ninclude_peer_dependencies = true\n\n[ecosystems.golang]\ninclude_test_dependencies = false\n</code></pre>"},{"location":"configuration/#environment-variables","title":"Environment Variables","text":"<p>Configuration can also be set through environment variables:</p> <pre><code># Set API keys\nexport DEPENDENCY_RISK_PROFILER_GITHUB_TOKEN=\"your-github-token\"\nexport DEPENDENCY_RISK_PROFILER_SNYK_TOKEN=\"your-snyk-token\"\n\n# Configure scoring weights\nexport DEPENDENCY_RISK_PROFILER_VULNERABILITY_WEIGHT=\"0.5\"\nexport DEPENDENCY_RISK_PROFILER_MAINTENANCE_WEIGHT=\"0.2\"\n\n# Set other options\nexport DEPENDENCY_RISK_PROFILER_CACHE_TTL_DAYS=\"14\"\nexport DEPENDENCY_RISK_PROFILER_OUTPUT_FORMAT=\"json\"\n</code></pre> <p>Environment variables take precedence over configuration files, and command-line options take precedence over both.</p>"},{"location":"configuration/#command-line-arguments","title":"Command-Line Arguments","text":"<p>Many configuration options can be set directly via command-line arguments:</p> <pre><code>dependency-risk-profiler analyze \\\n  --output-format json \\\n  --min-severity high \\\n  --include-dev-dependencies \\\n  --cache-ttl-days 14 \\\n  --vulnerability-weight 0.5 \\\n  path/to/project\n</code></pre>"},{"location":"configuration/#precedence-order","title":"Precedence Order","text":"<p>When multiple configuration sources are present, the following precedence is applied (from highest to lowest):</p> <ol> <li>Command-line arguments</li> <li>Environment variables</li> <li>Project-specific configuration file</li> <li>User configuration file</li> <li>Default values</li> </ol>"},{"location":"configuration/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"configuration/#custom-risk-scoring","title":"Custom Risk Scoring","text":"<p>You can fine-tune risk scoring to match your organization's risk tolerance:</p> <pre><code>[scoring]\n# Custom scoring model\nvulnerability_weight = 0.5   # Higher weight for security issues\nmaintenance_weight = 0.3    \ncommunity_weight = 0.1\nlicense_weight = 0.1\n\n# Custom risk thresholds\n[risk_levels]\nlow = 0.2    # Stricter threshold for low risk\nmedium = 0.5 # Stricter threshold for medium risk\n</code></pre>"},{"location":"configuration/#proxy-configuration","title":"Proxy Configuration","text":"<p>For organizations behind a proxy:</p> <pre><code>[network]\nproxy = \"http://proxy.example.com:8080\"\ntimeout_seconds = 30\nmax_retries = 3\n</code></pre>"},{"location":"configuration/#github-enterprise-support","title":"GitHub Enterprise Support","text":"<p>For GitHub Enterprise users:</p> <pre><code>[github]\napi_url = \"https://github.example.com/api/v3\"\nraw_url = \"https://github.example.com/raw\"\n</code></pre>"},{"location":"configuration/#ignoring-files-and-dependencies","title":"Ignoring Files and Dependencies","text":"<p>You can create an ignore file (<code>.dependency-risk-profiler-ignore</code>) to exclude certain dependencies or issues:</p> <pre><code># Ignore specific dependencies\nlodash\n# Ignore by pattern\ntest-*\n# Ignore specific versions\nexpress:4.17.1\n# Ignore specific issues\nCVE-2022-12345\n</code></pre>"},{"location":"configuration/#next-steps","title":"Next Steps","text":"<p>After configuring the tool, you may want to:</p> <ul> <li>Understand the Risk Scoring methodology</li> <li>Learn about Basic Usage patterns</li> <li>Explore Information Sources used by the tool</li> </ul>"},{"location":"getting-started/","title":"Getting Started","text":"<p>This guide will help you get started with Dependency Risk Profiler, a comprehensive tool for evaluating the health and risk of your project dependencies.</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.9 or higher</li> <li>Pip package manager</li> <li>Access to your project's dependency files (requirements.txt, package.json, go.mod, etc.)</li> </ul>"},{"location":"getting-started/#installation","title":"Installation","text":"<p>The simplest way to install Dependency Risk Profiler is via pip:</p> <pre><code>pip install dependency-risk-profiler\n</code></pre> <p>For more installation options, including development installation, see the Installation Guide.</p>"},{"location":"getting-started/#first-analysis","title":"First Analysis","text":"<p>To analyze a project:</p> <ol> <li>Navigate to your project directory</li> <li>Run the analyze command:</li> </ol> <pre><code>dependency-risk-profiler analyze .\n</code></pre> <p>The tool will automatically:</p> <ol> <li>Detect the project type (Python, Node.js, Go)</li> <li>Scan dependency manifests</li> <li>Analyze dependencies for various risk factors</li> <li>Display a risk summary</li> </ol>"},{"location":"getting-started/#understanding-the-results","title":"Understanding the Results","text":"<p>The output will include:</p> <ul> <li>Overall risk score and level</li> <li>Breakdown of risk by category</li> <li>Specific risk factors identified</li> <li>Recommended actions</li> </ul> <p>Example output:</p> <pre><code>Risk Analysis Report for my-project\n----------------------------------\nOverall Risk Score: 0.42 (LOW)\n\nRisk Categories:\n- Vulnerability: 0.2 (LOW)\n- Maintenance: 0.3 (LOW)\n- Community: 0.5 (MEDIUM)\n- License: 0.7 (MEDIUM)\n\nHigh Risk Dependencies:\n- outdated-lib (1.2.0): Last updated 3 years ago, no security policy\n- complex-framework (2.0.1): 5 known vulnerabilities, low community activity\n\nRecommendations:\n- Update outdated-lib to version 2.0.0+\n- Replace complex-framework or update to 2.1.3+ to fix vulnerabilities\n</code></pre>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Explore Basic Usage for more detailed usage information</li> <li>Learn how to Configure the tool for your specific needs</li> <li>Understand how Risk Scoring works</li> </ul>"},{"location":"installation/","title":"Installation Guide","text":"<p>Dependency Risk Profiler can be installed in several ways to accommodate different environments and use cases.</p>"},{"location":"installation/#standard-installation","title":"Standard Installation","text":"<p>For most users, installing via pip is the simplest approach:</p> <pre><code>pip install dependency-risk-profiler\n</code></pre> <p>This installs the core package with all required dependencies.</p>"},{"location":"installation/#installation-with-optional-features","title":"Installation with Optional Features","text":"<p>Dependency Risk Profiler has several optional feature sets:</p> <pre><code># Install with visualization support\npip install \"dependency-risk-profiler[visualization]\"\n\n# Install with development tools\npip install \"dependency-risk-profiler[dev]\"\n\n# Install with all optional features\npip install \"dependency-risk-profiler[dev,visualization]\"\n</code></pre>"},{"location":"installation/#quick-install-script","title":"Quick Install Script","text":"<p>For a guided installation experience, you can use the quick install script:</p> <pre><code># On Linux/macOS\ncurl -sSL https://raw.githubusercontent.com/williamzujkowski/dependency-risk-profiler/main/quickinstall.py | python -\n\n# On Windows (PowerShell)\n(Invoke-WebRequest -Uri https://raw.githubusercontent.com/williamzujkowski/dependency-risk-profiler/main/quickinstall.py -UseBasicParsing).Content | python -\n</code></pre> <p>The script will: 1. Check your Python version 2. Create a virtual environment (optional) 3. Install the package with your chosen options 4. Run a quick verification test</p>"},{"location":"installation/#development-installation","title":"Development Installation","text":"<p>For contributors or those who want the latest development version:</p> <pre><code># Clone the repository\ngit clone https://github.com/williamzujkowski/dependency-risk-profiler.git\ncd dependency-risk-profiler\n\n# Create and activate a virtual environment (recommended)\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Install in development mode with all dependencies\npip install -e \".[dev,visualization]\"\n\n# Install pre-commit hooks (for contributors)\npre-commit install\n</code></pre>"},{"location":"installation/#system-requirements","title":"System Requirements","text":"<ul> <li>Python Version: 3.9 or higher</li> <li>Operating Systems: Windows, macOS, Linux</li> <li>Disk Space: ~100MB (including dependencies)</li> <li>Additional Requirements:</li> <li>For Go analysis: Access to public Go module proxies</li> <li>For visualization: Additional ~50MB for graphical dependencies</li> </ul>"},{"location":"installation/#verifying-installation","title":"Verifying Installation","text":"<p>After installation, verify that the tool is working correctly:</p> <pre><code># Check the installed version\ndependency-risk-profiler --version\n\n# Run a basic command\ndependency-risk-profiler list-ecosystems\n</code></pre>"},{"location":"installation/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter installation issues:</p> <ul> <li>Dependency Conflicts: Try installing in a fresh virtual environment</li> <li>Permission Errors: Use <code>pip install --user</code> or consider using a virtual environment</li> <li>Missing Compiler: Some dependencies may require a C compiler; install the appropriate development tools for your OS</li> <li>Connectivity Issues: Ensure you have internet access for downloading dependencies</li> </ul> <p>For more help, see the Contributing Guide or open an issue.</p>"},{"location":"development/CLAUDE/","title":"CLAUDE.md","text":"<p>This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.</p>"},{"location":"development/CLAUDE/#build-setup-commands","title":"Build &amp; Setup Commands","text":"<pre><code># Create and activate virtual environment\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Install dependencies\npip install -e \".[dev]\"\n\n# Install pre-commit hooks\npre-commit install\n</code></pre>"},{"location":"development/CLAUDE/#lint-test-commands","title":"Lint &amp; Test Commands","text":"<pre><code># Format code\nblack .\nisort .\n\n# Lint code\nflake8\nmypy .\n\n# Run all tests\npytest\n\n# Run a single test\npytest testing/unit/test_file.py::test_function_name\n\n# Run tests with coverage\npytest --cov=src\n</code></pre>"},{"location":"development/CLAUDE/#documentation-commands","title":"Documentation Commands","text":"<pre><code># Install documentation dependencies\npip install -e \".[docs]\"\n\n# Preview documentation site (with live reloading)\nmkdocs serve\n\n# Build static documentation site\nmkdocs build\n\n# Deploy to GitHub Pages (if configured)\nmkdocs gh-deploy\n</code></pre>"},{"location":"development/CLAUDE/#code-style-guidelines","title":"Code Style Guidelines","text":"<ul> <li>Use PEP 8 standards with 88 character line length (Black default)</li> <li>Snake case for variables, functions, methods: <code>user_count</code>, <code>calculate_total()</code></li> <li>Pascal case for classes: <code>DependencyParser</code>, <code>RiskProfiler</code></li> <li>Type annotations required for all functions and methods</li> <li>Follow Google-style docstrings</li> <li>Keep functions focused and under 50 lines when possible</li> <li>Handle exceptions with custom exception classes</li> <li>Organize imports: stdlib, third-party, local (handled by isort)</li> </ul>"},{"location":"development/PROMPT/","title":"Claude Prompts","text":"<p>Prompt for Code Creation LLM: Build an Open-Source Dependency Risk Profiler CLI Tool</p> <p>Overview:</p> <p>Create a command-line tool (CLI) called \u201cDependency Risk Profiler\u201d that goes beyond traditional vulnerability scanners by assessing the overall \u201chealth\u201d of a project\u2019s open-source dependencies. The tool will analyze a software project\u2019s dependency manifest (e.g., package-lock.json for Node.js, requirements.txt for Python, go.mod for Go) and evaluate each dependency according to quality and maintenance risk indicators. This profiler should help developers quickly identify libraries that may be outdated, undermaintained, or potentially risky\u2014even if they have no reported CVEs.</p> <p>Core Features and Requirements:</p> <ol> <li>Input &amp; File Parsing:</li> <li>The tool should accept a path to a dependency file (or multiple files) as an input argument.</li> <li>It must support common manifest or lock files:<ul> <li>Node.js: <code>package-lock.json</code></li> <li>Python: <code>requirements.txt</code> (and optionally, <code>Pipfile.lock</code>)</li> <li>Go: <code>go.mod</code></li> </ul> </li> <li> <p>Modular design is preferred so that support for additional package managers can be added later.</p> </li> <li> <p>Data Collection for Each Dependency:    For each dependency extracted from the manifest, the tool should attempt to collect and compute the following metrics without requiring any API credentials (using only anonymous access or local analysis):</p> </li> <li>Version Comparison:<ul> <li>Determine the installed version versus the latest available version (e.g., by scraping package repositories or inspecting local metadata).</li> </ul> </li> <li>Update Recency:<ul> <li>Calculate how long ago the dependency was last updated (e.g., using commit or release date information). If needed, the tool can clone the dependency\u2019s repository locally to inspect its commit history.</li> </ul> </li> <li>Maintenance and Community Indicators:<ul> <li>Check whether the project appears to be maintained by a single maintainer or by a team (for example, by estimating the number of contributors or checking if multiple maintainer names appear).</li> <li>Flag if the dependency is marked as deprecated (e.g., from repository metadata or tags).</li> <li>Optionally, check for the presence of standard repository files that indicate healthy maintenance (e.g., existence of tests, CI configuration files, contribution guidelines).</li> </ul> </li> <li> <p>Public Exploit Information:</p> <ul> <li>Optionally, scan for any public exploit or vulnerability warnings (this can be integrated by scraping public feeds or searching for alerts associated with the package, always using publicly available data).</li> </ul> </li> <li> <p>Risk Scoring and Output:</p> </li> <li>Compute a composite risk score for each dependency based on weighted factors:<ul> <li>Example weights might be: </li> <li>Staleness: Longer time since last update increases risk.</li> <li>Single Maintainer: Fewer maintainers increases risk.</li> <li>Deprecated Status: A deprecated flag adds a significant risk factor.</li> <li>Exploit Info: Presence of any public exploit info further increases the risk.</li> </ul> </li> <li>Display the results in a clear, color-coded report in the terminal. For example:<ul> <li>Green for low-risk dependencies.</li> <li>Yellow for moderate risk.</li> <li>Red for high-risk dependencies.</li> </ul> </li> <li> <p>Optionally, support output in JSON format as well.</p> </li> <li> <p>CLI Interface and Options:</p> </li> <li>The CLI should include command-line arguments to specify:<ul> <li>The file path(s) to dependency manifests.</li> <li>The output format (default colorized text report; an option for JSON).</li> <li>Verbosity or \u201cdebug\u201d mode for more detailed logging.</li> <li>Optional parameters such as custom thresholds for risk scoring.</li> </ul> </li> <li> <p>Provide a helpful usage message when invoked with a <code>--help</code> flag.</p> </li> <li> <p>Technical and Architectural Requirements:</p> </li> <li>Language: The implementation can be in Python (or another language, but Python is recommended for rapid prototyping and ease of handling file I/O and HTTP scraping).</li> <li>Modular Structure: Structure your code so that parsing logic, data fetching/analysis, risk scoring, and CLI output are contained in separate modules or functions. This will make future extension easier.</li> <li>No External Credentials: All data-gathering must be done anonymously (e.g., scraping public repositories or using public endpoints) to avoid needing API keys or logins.</li> <li>Error Handling: Implement robust error handling\u2014if a dependency cannot be analyzed (e.g., due to missing data), the tool should log a warning but continue processing others.</li> <li>Documentation: Include inline documentation and a README section within the code comments that explains how to run the tool and extend its functionality.</li> </ol> <p>Example Usage Scenario:</p> <p>A developer runs the command: <pre><code>$ dependency-risk-profiler --manifest /path/to/package-lock.json --output terminal\n</code></pre> The tool parses the package-lock.json file, evaluates each dependency according to the metrics listed above, computes risk scores, and then outputs a color-coded report that might look like: <pre><code>Dependency         Installed   Latest    Last Update     Maintainers    Risk Score    Status\n---------------------------------------------------------------------------------------------\nlodash             4.17.15     4.17.21   6 months ago    3              2.1/5         LOW\nsome-old-lib       1.0.0       1.2.0     4 years ago     1              4.7/5         HIGH (Outdated)\n...\n</code></pre> Optionally, the developer can also get the output in JSON format by adding a flag <code>--output json</code>.</p> <p>Final Instruction: Using the above specifications, produce a complete, well-documented script that implements this CLI tool, keeping the code modular and maintainable. Include error handling, logging, and a user-friendly CLI interface.</p> <p>Feel free to ask for clarifications or modifications if needed. This prompt should guide the code creation LLM to generate a solution that aligns closely with your design objectives for assessing dependency health and supply chain risk.</p>"},{"location":"development/RELEASE_PROCESS/","title":"Release Process","text":"<p>This document explains the release process for the Dependency Risk Profiler project.</p>"},{"location":"development/RELEASE_PROCESS/#automated-release-pipeline","title":"Automated Release Pipeline","text":"<p>The project uses GitHub Actions for an automated CI/CD pipeline to handle releases. The workflow is defined in <code>.github/workflows/release.yml</code> and is triggered when a new version tag is pushed to the repository.</p>"},{"location":"development/RELEASE_PROCESS/#creating-a-new-release","title":"Creating a New Release","text":"<p>To create a new release, follow these steps:</p>"},{"location":"development/RELEASE_PROCESS/#1-prepare-for-release","title":"1. Prepare for Release","text":"<ol> <li>Ensure all intended changes are merged to the <code>main</code> branch</li> <li>Make sure all tests pass and the CI pipeline is green</li> <li>Update the version number in <code>src/dependency_risk_profiler/__init__.py</code>:</li> </ol> <pre><code>__version__ = \"X.Y.Z\"  # Update to the new version\n</code></pre> <ol> <li>Commit this change with a message like <code>\"chore: bump version to X.Y.Z\"</code></li> </ol>"},{"location":"development/RELEASE_PROCESS/#2-create-and-push-a-version-tag","title":"2. Create and Push a Version Tag","text":"<p>Create a new tag following Semantic Versioning principles:</p> <ul> <li>Patch releases (bug fixes that don't change the API): <code>vX.Y.Z</code> \u2192 <code>vX.Y.Z+1</code></li> <li>Minor releases (backward-compatible new features): <code>vX.Y.Z</code> \u2192 <code>vX.Y+1.0</code></li> <li>Major releases (breaking changes): <code>vX.Y.Z</code> \u2192 <code>vX+1.0.0</code></li> </ul> <pre><code># Example for a patch release\ngit tag v0.2.1\ngit push origin v0.2.1\n\n# Example for a minor release\ngit tag v0.3.0\ngit push origin v0.3.0\n\n# Example for a major release\ngit tag v1.0.0\ngit push origin v1.0.0\n</code></pre>"},{"location":"development/RELEASE_PROCESS/#3-monitor-the-release-workflow","title":"3. Monitor the Release Workflow","text":"<p>Once the tag is pushed, the release workflow will automatically:</p> <ol> <li>Build the Python package (wheel and sdist)</li> <li>Generate release notes based on commits since the last release</li> <li>Create a GitHub Release with the generated notes</li> <li>Upload the package files to the GitHub Release</li> <li>Publish the package to PyPI</li> <li>Update the documentation site</li> </ol> <p>You can monitor the workflow's progress in the \"Actions\" tab of the GitHub repository.</p>"},{"location":"development/RELEASE_PROCESS/#4-verify-the-release","title":"4. Verify the Release","text":"<p>After the workflow completes successfully:</p> <ol> <li> <p>Check that the new version is available on PyPI:    <pre><code>pip install dependency-risk-profiler==X.Y.Z\n</code></pre></p> </li> <li> <p>Verify the GitHub Release was created with the correct artifacts:</p> </li> <li>Visit the \"Releases\" page on GitHub</li> <li> <p>Ensure both the wheel and source distribution are attached</p> </li> <li> <p>Confirm the documentation site has been updated:</p> </li> <li>Visit https://williamzujkowski.github.io/dependency-risk-profiler/</li> <li>Check that any documentation changes are reflected</li> </ol>"},{"location":"development/RELEASE_PROCESS/#release-requirements","title":"Release Requirements","text":"<p>To perform releases, the following requirements must be met:</p>"},{"location":"development/RELEASE_PROCESS/#pypi-publishing","title":"PyPI Publishing","text":"<p>A PyPI API token must be stored as a repository secret named <code>PYPI_API_TOKEN</code>. This token should have permission to publish to the PyPI project.</p> <p>To create a new token: 1. Log into PyPI 2. Go to Account Settings \u2192 API tokens 3. Create a new token with upload permissions for the <code>dependency-risk-profiler</code> project 4. Add the token as a repository secret in GitHub (Settings \u2192 Secrets \u2192 Actions \u2192 New repository secret)</p>"},{"location":"development/RELEASE_PROCESS/#github-permissions","title":"GitHub Permissions","text":"<p>The workflow requires write permission to: - Repository contents (to create releases) - GitHub Pages (to deploy documentation)</p> <p>These permissions are configured in the workflow file and should not require additional setup.</p>"},{"location":"development/RELEASE_PROCESS/#handling-release-failures","title":"Handling Release Failures","text":"<p>If the release workflow fails:</p> <ol> <li>Check the workflow logs to identify the issue</li> <li>Fix the problem in a new PR to the <code>main</code> branch</li> <li>If needed, delete the failed GitHub tag:    <pre><code>git tag -d vX.Y.Z\ngit push --delete origin vX.Y.Z\n</code></pre></li> <li>Try the release process again with the fixes in place</li> </ol>"},{"location":"development/RELEASE_PROCESS/#release-notes","title":"Release Notes","text":"<p>Release notes are automatically generated from commit messages between the previous and new tag. To ensure high-quality release notes:</p> <ol> <li>Use clear, descriptive commit messages</li> <li>Follow the Conventional Commits format when possible:</li> <li><code>feat:</code> for new features</li> <li><code>fix:</code> for bug fixes</li> <li><code>docs:</code> for documentation changes</li> <li><code>chore:</code> for maintenance tasks</li> <li><code>refactor:</code> for code refactoring</li> <li><code>test:</code> for test additions or modifications</li> </ol>"},{"location":"development/RELEASE_PROCESS/#post-release-tasks","title":"Post-Release Tasks","text":"<p>After a successful release:</p> <ol> <li>Announce the release in appropriate channels</li> <li>Update the project roadmap or milestones, if applicable</li> <li>Start planning the next release cycle</li> </ol>"},{"location":"enhancement/","title":"Enhancement Proposals","text":"<p>This directory contains documentation of enhancement proposals and implementation plans for the Dependency Risk Profiler.</p>"},{"location":"enhancement/#files","title":"Files","text":"<ul> <li><code>ENHANCEMENTS2.md</code> - Second batch of enhancement proposals</li> <li><code>ENHANCEMENTS3.md</code> - Third batch of enhancement proposals, including:</li> <li>Enhanced error handling and robustness</li> <li>Plugin-like mechanism for ecosystem parsers</li> <li>Disk-based caching for vulnerability data</li> <li>Parallelized repository analysis</li> <li>Configuration file support for risk scoring</li> <li>CLI refactoring</li> <li>Single vs. multi-maintainer analysis</li> <li>Automated documentation generation</li> </ul>"},{"location":"enhancement/#purpose","title":"Purpose","text":"<p>These files track proposed improvements to the Dependency Risk Profiler, their implementation status, and implementation notes. They serve as a roadmap for the project's development.</p>"},{"location":"enhancement/ENHANCEMENTS2/","title":"Phase 2 Enhancements","text":"<p>Below are a few example prompts you can provide to a code generation LLM. Each prompt is designed to instruct the model to generate code (or configuration files) that implements secure code signing best practices combined with robust release engineering practices.</p> <p>Prompt 1: CI/CD Pipeline with Integrated Code Signing</p> <p>*\u201cGenerate a YAML configuration for a CI/CD pipeline (e.g., a GitHub Actions workflow) that performs the following steps:</p> <ul> <li>Checks out the source code from Git.</li> <li>Runs unit, integration, and security tests.</li> <li>Builds a reproducible binary package ensuring hermetic builds.</li> <li>Generates a unique build identifier (using Semantic Versioning).</li> <li>Automatically signs the final build artifact using a secure code signing process that incorporates the following best practices:</li> <li>Uses a separate release-signing key stored in a Hardware Security Module (HSM) (simulate this by calling an external signing service function).</li> <li>Includes a time-stamp in the signature.</li> <li>Logs all signing activities for audit purposes.</li> <li>Pushes the signed artifact to an artifact repository.</li> </ul> <p>Ensure that the configuration is modular so that the signing steps can be swapped out or extended, and include comments explaining each stage. Use secret-management best practices (e.g., reference secrets from environment variables rather than embedding them directly).\u201d*</p> <p>Prompt 2: Secure Code Signing Script in Python</p> <p>*\u201cWrite a Python script that implements a secure code signing function for build artifacts. The script should:</p> <ol> <li>Read an artifact (e.g., a .zip file) and compute its cryptographic hash.</li> <li>Perform a virus/malware scan on the artifact before signing.</li> <li>Retrieve a signing key from a secure storage system (simulate this as a function that returns a key from an HSM, ensuring that the key is never exposed).</li> <li>Digitally sign the artifact\u2019s hash using the signing key, and include a trusted timestamp obtained from a timestamping service.</li> <li>Log all signing operations (including the artifact name, build identifier, and timestamp) to a secure log file.</li> <li>Differentiate between test-signing and release-signing modes based on a command-line flag (e.g., <code>--mode test</code> vs. <code>--mode release</code>).</li> </ol> <p>Include error handling for key retrieval failures, virus scan failures, and signing errors, and comment your code extensively.\u201d*</p> <p>Prompt 3: Artifact Packaging and Versioning Script</p> <p>*\u201cDevelop a script (in a language of your choice, e.g., Python) that automates the packaging of software releases. The script should:</p> <ul> <li>Read the current version from a configuration file and increment it following Semantic Versioning rules.</li> <li>Build the artifact (simulate a build process by packaging files into a zip archive).</li> <li>Generate a checksum (e.g., SHA-256 hash) for the build.</li> <li>Integrate with the secure code signing script (from Prompt 2) to sign the artifact.</li> <li>Save the signed artifact along with its checksum and version metadata into a structured artifact repository (simulate this with file system directories organized by version).</li> <li>Output release notes summarizing the version, signing timestamp, and any encountered warnings or errors.</li> </ul> <p>Ensure your script allows for extensibility (e.g., later replacing the packaging method, incorporating additional metadata, or integrating with a cloud artifact storage system). Provide detailed comments and usage instructions.\u201d*</p> <p>Prompt 4: Comprehensive Release Build Script with Security Gate</p> <p>*\u201cGenerate a Bash (or Python) script that ties together multiple steps of a secure release process. The script should:</p> <ol> <li>Pull the latest code from a version-controlled repository.</li> <li>Run a suite of automated tests.</li> <li>Build the software artifact in a reproducible manner.</li> <li>Perform virus/malware scanning on the build output.</li> <li>Call an external Python code-signing utility (see Prompt 2) to digitally sign the artifact, ensuring that the signing process uses an HSM-protected key and appends a timestamp.</li> <li>Log all operations (build start/end times, test results, virus scan status, signing success/failure, and timestamp) to a centralized audit log.</li> <li>Handle errors gracefully (if tests fail, virus scan fails, or signing fails, the script should exit and report the problem).</li> <li>Support configurable parameters via command-line arguments (such as specifying the build mode, version bump type, or artifact output directory).</li> </ol> <p>Include comments and instructions that help a user integrate this script into a larger CI/CD system, ensuring it\u2019s production ready.\u201d*</p> <p>Each of these prompts is self-contained and directs a code generation LLM to produce code for various parts of a secure release engineering and code signing process. You can adapt the prompts or combine elements of them to match the specifics of your technology stack and organizational requirements.</p> <p>Would you like further refinements or additional prompts related to a specific technology or aspect of the release process?</p>"},{"location":"enhancement/ENHANCEMENTS3/","title":"Enhancement Roadmap","text":"<p>Below are the enhancements planned for the dependency-risk-profiler project. Implemented features are marked with \u2705.</p>"},{"location":"enhancement/ENHANCEMENTS3/#implementation-status-summary","title":"Implementation Status Summary:","text":"<p>Completed: - \u2705 We successfully implemented the Plugin-Like Mechanism (Prompt 2) to provide a more systematic way to register and detect ecosystem parsers. - \u2705 We added Disk-Based Caching for Vulnerability Data (Prompt 3) that stores data locally to reduce network calls across runs. - \u2705 We enhanced Error Handling and Robustness (Prompt 1) with retry mechanisms and better error recovery.</p> <p>Remaining Enhancements: - Parallelized Repository Analysis (Prompt 4) - Configuration File Support (Prompt 5) - CLI Refactoring with Typer/Click (Prompt 6) - Single vs. Multi-Maintainer Checking (Prompt 7) - Automated Documentation Generation (Prompt 8)</p> <p>Note: ENHANCEMENTS2.md contains requirements for the Secure Code Signing feature that is planned but not yet implemented.</p>"},{"location":"enhancement/ENHANCEMENTS3/#prompt-1-enhanced-error-handling-and-robustness-implemented","title":"\u2705 Prompt 1: Enhanced Error Handling and Robustness (IMPLEMENTED)","text":"<p>\"Refactor the code to improve error handling and resilience for external network calls and subprocess operations. Specifically:</p> <ol> <li>Wrap <code>requests.get</code> and <code>requests.post</code> in a retry mechanism (e.g., using an exponential backoff strategy).</li> <li>Add try/except blocks around <code>subprocess.run</code> calls to catch <code>subprocess.CalledProcessError</code> and log a warning instead of crashing the program.</li> <li>Gracefully handle missing or malformed data from external calls (e.g., if JSON responses lack expected fields, log the issue and continue without halting).</li> <li>Document each new exception or fallback path in docstrings or inline comments, ensuring we clearly explain how partial failures are handled.</li> </ol> <p>Implementation notes: - Added exponential backoff retry mechanism for all network requests in vulnerability sources - Improved error handling for different types of errors (client errors, server errors, connectivity) - Added detailed error logging for better debugging</p>"},{"location":"enhancement/ENHANCEMENTS3/#prompt-2-plugin-like-mechanism-for-new-ecosystems-implemented","title":"\u2705 Prompt 2: Plugin-Like Mechanism for New Ecosystems (IMPLEMENTED)","text":"<p>\"Implement a plugin or registry pattern so that adding support for new ecosystems is more systematic. Specifically:</p> <ol> <li>Create a 'plugin registry' (e.g., in <code>BaseParser</code>) where each parser (NodeJSParser, PythonParser, etc.) can register itself with a unique ecosystem identifier.</li> <li>Modify <code>get_parser_for_file</code> so it loops through the registered plugins to detect the best parser, rather than having large if/else blocks.</li> <li>Allow external modules to provide new parser/analyzer pairs by registering them at runtime (e.g., <code>EcosystemRegistry.register_parser('rust', RustParser)</code>).</li> <li>Update the CLI to display a list of available ecosystems if a user tries to parse an unrecognized manifest file.</li> </ol> <p>Implementation notes: - Created an <code>EcosystemRegistry</code> class to manage parsers and file patterns - Implemented file pattern matching with three strategies (filename, extension, content) - Updated CLI to display available ecosystems when a user tries to parse an unrecognized manifest file - Added <code>--list-ecosystems</code> command to display all supported ecosystems</p>"},{"location":"enhancement/ENHANCEMENTS3/#prompt-3-disk-based-caching-for-vulnerability-data-implemented","title":"\u2705 Prompt 3: Disk-Based Caching for Vulnerability Data (IMPLEMENTED)","text":"<p>\"Augment the existing <code>vulnerabilities/aggregator.py</code> module to store fetched vulnerability data on disk (rather than in memory only), enabling reuse across multiple runs. Specifically:</p> <ol> <li>Implement a simple file-based cache using JSON (e.g., stored in a <code>.vuln_cache</code> directory).</li> <li>Load cached data if available and recent (e.g., within 24 hours), instead of making new network calls.</li> <li>Implement a safe fallback so that if the cached file is corrupt or out-of-date, the code seamlessly fetches fresh data.</li> <li>Allow the user to override or clear the cache (e.g., <code>--no-cache</code> command-line flag or an environment variable).</li> <li>Document in the docstrings how the caching logic works, and update the logging to indicate whether data is served from cache or from a fresh request.</li> </ol> <p>Implementation notes: - Added <code>VulnerabilityCache</code> class for disk-based caching in <code>~/.dependency_risk_profiler/vuln_cache/</code> - Implemented cache expiry, validation, and robust error handling - Added <code>--no-cache</code> and <code>--clear-cache</code> CLI options - Maintained backward compatibility with the in-memory cache - Added comprehensive unit tests for the cache system</p>"},{"location":"enhancement/ENHANCEMENTS3/#prompt-4-parallelized-or-asynchronous-repository-analysis","title":"Prompt 4: Parallelized or Asynchronous Repository Analysis","text":"<p>\"Refactor the repository-cloning and data-fetching steps to run concurrently, reducing overall execution time in large projects. Specifically:</p> <ol> <li>Use Python's <code>asyncio</code> or <code>concurrent.futures.ThreadPoolExecutor</code> to clone multiple repositories in parallel.</li> <li>Add a configuration parameter (<code>max_concurrent_clones</code>, defaulting to 4) so that we limit concurrency for environment constraints.</li> <li>Refactor analyzers (e.g., in <code>analyzers/common.py</code>) so that <code>clone_repo</code>, <code>get_last_commit_date</code>, etc., do not block the main thread. Each step can be asynchronous or in a worker pool.</li> <li>Include error-handling so that if some tasks fail (e.g., a repo clone times out), the rest of the tasks still continue. Log partial failures but keep going.</li> <li>Maintain a global concurrency limit so that we don't spawn too many processes, especially in large monorepos.</li> </ol>"},{"location":"enhancement/ENHANCEMENTS3/#prompt-5-configuration-file-support-for-risk-scoring","title":"Prompt 5: Configuration File Support for Risk Scoring","text":"<p>\"Add a simple configuration file feature to manage risk scoring weights and other user settings. Specifically:</p> <ol> <li>Create a config loader (e.g., <code>config.py</code>) that looks for a YAML or JSON file (<code>dependency_risk_config.yaml</code> or <code>json</code>) in the current directory or a user-specified path.</li> <li>Extend the CLI to accept a <code>--config</code> argument which overrides default or command-line-provided values. If no config file is found, proceed with existing defaults.</li> <li>Merge any config file values with the existing CLI flags so that CLI flags take precedence for quick one-off changes.</li> <li>Document the structure of the config file with an example snippet (e.g., keys for staleness_weight, maintainers_weight, etc.).</li> <li>Add test cases verifying that the config file is correctly loaded, overrides default values, and merges properly if partial config keys are missing.</li> </ol>"},{"location":"enhancement/ENHANCEMENTS3/#prompt-6-refactoring-the-cli-with-typer-or-click","title":"Prompt 6: Refactoring the CLI with Typer or Click","text":"<p>\"Refactor the command-line interface to use a more modern framework (e.g., Typer or Click) to improve code readability and user help text. Specifically:</p> <ol> <li>Create a new <code>cli.py</code> that uses Typer for subcommands (<code>analyze</code>, <code>score</code>, <code>visualize</code>, <code>trends</code>, <code>release</code>, etc.).</li> <li>Organize subcommands so that each functional area (e.g., <code>dependency-risk-profiler analyze &lt;options&gt;</code>) has its own subcommand help section with typed arguments.</li> <li>Maintain backward compatibility if possible, or at least provide deprecation messaging for old flags.</li> <li>Automatically generate help text from function docstrings or parameter annotations (Typer feature).</li> <li>Include error codes or exit statuses for known error conditions (e.g., missing manifest).</li> </ol>"},{"location":"enhancement/ENHANCEMENTS3/#prompt-7-single-maintainer-vs-multi-maintainer-checking","title":"Prompt 7: Single Maintainer vs. Multi-Maintainer Checking","text":"<p>\"Enhance the logic that checks whether a package is maintained by a single individual or a team. Specifically:</p> <ol> <li>Add checks that read the repository's contributor/committer data (already shallow cloned) to count unique authors.</li> <li>Compare the number of unique authors, using thresholds for 1=single, 2-3=small, 4+ = moderate, 10+ = large.</li> <li>In the risk scoring give a higher penalty to single-maintainer dependencies, a smaller penalty to small teams, and no penalty to large communities.</li> <li>Log the results in the final terminal output (e.g., \"Maintainers: 3 \u2192 moderate\") and reflect that in the final risk factors list.</li> <li>Write or update tests where you clone example repos with dummy commits so that at least one test covers the scenario of single vs. multiple maintainers.</li> </ol>"},{"location":"enhancement/ENHANCEMENTS3/#prompt-8-automated-documentation-generation","title":"Prompt 8: Automated Documentation Generation","text":"<p>\"Set up automated API documentation generation so that docstrings are reflected in user-friendly docs. Specifically:</p> <ol> <li>Add a Sphinx or MkDocs configuration in a <code>docs/</code> folder.</li> <li>Scan the <code>src/dependency_risk_profiler</code> directory to autodoc all public classes and functions.</li> <li>Generate an index page summarizing the modules and sub-packages (e.g., <code>CLI &amp; Parsers</code>, <code>Risk Scoring</code>, <code>Analyzer Plugins</code>, etc.).</li> <li>In README and/or <code>docs/README.md</code>, instruct contributors how to run <code>sphinx-build</code> (or <code>mkdocs build</code>) to regenerate docs.</li> <li>Optionally set up a GitHub Actions workflow to automatically build and deploy the docs to GitHub Pages if the build is successful.</li> </ol>"},{"location":"enhancement/Improvements/","title":"Improvement Ideas","text":"<p>Improvements.md</p> <p>Below are concise, copy\u2011and\u2011pasteable prompts you can feed into a code\u2011generation LLM to implement each of the recommended improvements:</p>"},{"location":"enhancement/Improvements/#1-migrate-to-pyprojecttoml","title":"1. Migrate to <code>pyproject.toml</code>","text":"<pre><code>Prompt: Refactor the repository to consolidate all configuration into a single `pyproject.toml`.  \n- Move package metadata from `setup.py`, `setup.cfg`, and `MANIFEST.in` into `[project]` or `[tool.poetry]` sections.  \n- Add a `[build-system]` table specifying the build backend (e.g. `setuptools.build_meta` or `poetry.core.masonry.api`).  \n- Include dev\u2011dependencies under `[project.optional-dependencies.dev]` (or `[tool.poetry.dev-dependencies]`).  \n- Configure Black, isort, Flake8, and Mypy under `[tool.black]`, `[tool.isort]`, `[tool.flake8]`, and `[tool.mypy]`.  \n</code></pre>"},{"location":"enhancement/Improvements/#2-remove-legacy-configuration-files","title":"2. Remove Legacy Configuration Files","text":"<pre><code>Prompt: Delete obsolete packaging and config files now covered by `pyproject.toml`.  \n- Remove `setup.py`, `setup.cfg`, `MANIFEST.in`.  \n- Delete standalone `.flake8` and `mypy.ini`.  \n- Archive or drop any `install.sh`/`install.bat` wrappers if installation is fully handled by `pip install .`.  \n</code></pre>"},{"location":"enhancement/Improvements/#3-add-a-github-actions-ci-workflow","title":"3. Add a GitHub Actions CI Workflow","text":"<pre><code>Prompt: Create `.github/workflows/ci.yml` to run on every push and pull request on `main`.  \n- Use `actions/checkout@v3` and `actions/setup-python@v4` to install Python 3.8\u20133.11.  \n- Install dependencies with `pip install .[dev]`.  \n- Run `pre-commit run --all-files`, `flake8 src/`, `mypy src/`, and `pytest --junitxml=report.xml --cov=src`.  \n- Upload coverage report as an artifact.  \n</code></pre>"},{"location":"enhancement/Improvements/#4-configure-dependabot-for-dependency-updates","title":"4. Configure Dependabot for Dependency Updates","text":"<pre><code>Prompt: Add `.github/dependabot.yml` to enable automatic version updates.  \n- Monitor `pip` ecosystem weekly.  \n- Target directory `/`.  \n- Auto\u2011merge patch-level updates.  \n</code></pre>"},{"location":"enhancement/Improvements/#5-enable-precommit-hooks","title":"5. Enable Pre\u2011commit Hooks","text":"<pre><code>Prompt: Define `.pre-commit-config.yaml` with hooks for Black, isort, Flake8, and Mypy.  \n- Use `repo: psf/black`, `repo: pre-commit/mirrors-isort`, `repo: pycqa/flake8`, `repo: mypy/mypy`.  \n- Enforce formatting and static checks before every commit.  \n</code></pre>"},{"location":"enhancement/Improvements/#6-integrate-coverage-reporting","title":"6. Integrate Coverage Reporting","text":"<pre><code>Prompt: Update `pytest.ini` or `pyproject.toml` to include `pytest-cov` settings.  \n- On test runs, generate HTML and XML coverage reports.  \n- Fail CI if overall coverage falls below 90%.  \n- Add a coverage badge to `README.md`.  \n</code></pre>"},{"location":"enhancement/Improvements/#7-add-bandit-security-scanning","title":"7. Add Bandit Security Scanning","text":"<pre><code>Prompt: In the CI workflow, insert a step to run `bandit -r src/ -f html -o bandit.html`.  \n- Configure `.bandit.yml` to adjust severity thresholds.  \n- Fail the build on any high\u2011severity findings.  \n</code></pre>"},{"location":"enhancement/Improvements/#8-automate-releases-via-github-actions","title":"8. Automate Releases via GitHub Actions","text":"<pre><code>Prompt: Create `.github/workflows/release.yml` triggered on version tag pushes (`v*.*.*`).  \n- Use `actions/create-release@v1`, build wheel and sdist, then `actions/upload-release-asset@v1`.  \n- Publish to PyPI using `pypa/gh-action-pypi-publish@release-v1`.  \n</code></pre>"},{"location":"enhancement/Improvements/#9-generate-a-changelog-automatically","title":"9. Generate a Changelog Automatically","text":"<pre><code>Prompt: Add a step in `release.yml` to run `github-changelog-generator \u2014future-release v$GITHUB_REF_NAME`.  \n- Output to `CHANGELOG.md` before creating the GitHub release.  \n</code></pre>"},{"location":"enhancement/Improvements/#10-optional-adopt-poetry-for-packaging","title":"10. (Optional) Adopt Poetry for Packaging","text":"<pre><code>Prompt: Replace setuptools with Poetry:  \n- Run `poetry init` to create `pyproject.toml`.  \n- Define project dependencies and dev-dependencies.  \n- Update CI to use `poetry install` and `poetry run`.  \n</code></pre>"},{"location":"project_standards/TESTING_IMPLEMENTATION/","title":"TESTING_IMPLEMENTATION.md","text":"<p>This document explains how the comprehensive test suite was implemented according to the standards outlined in TESTING_STANDARDS.md.</p>"},{"location":"project_standards/TESTING_IMPLEMENTATION/#overview","title":"Overview","text":"<p>The test suite follows the five categories specified in the testing standards:</p> <ol> <li>Hypothesis Tests for Behavior Validation</li> <li>Regression Tests for Known Fail States</li> <li>Benchmark Tests with SLA Enforcement</li> <li>Grammatical Evolution for Fuzzing + Edge Discovery</li> <li>Structured Logs for Agent Feedback</li> </ol>"},{"location":"project_standards/TESTING_IMPLEMENTATION/#implementation-details","title":"Implementation Details","text":""},{"location":"project_standards/TESTING_IMPLEMENTATION/#file-structure","title":"File Structure","text":"<p>Two primary test files were created:</p> <ul> <li><code>tests/test_comprehensive_vulnerability_aggregator.py</code> - Tests for the vulnerability aggregation component</li> <li><code>tests/test_comprehensive_risk_scorer.py</code> - Tests for the risk scoring system</li> </ul>"},{"location":"project_standards/TESTING_IMPLEMENTATION/#1-hypothesis-tests-for-behavior-validation","title":"1. Hypothesis Tests for Behavior Validation","text":"<p>Tests in this category validate core behaviors of the system:</p> <ul> <li><code>test_normalize_cvss_score_valid_values</code> - Validates correct normalization of CVSS scores</li> <li><code>test_severity_to_score_mapping</code> - Ensures severity strings map to correct numerical scores</li> <li><code>test_staleness_score_calculation</code> - Validates calculation of staleness based on update dates</li> <li><code>test_maintainer_score_calculation</code> - Tests scoring based on maintainer count</li> <li><code>test_version_difference_score_calculation</code> - Tests version comparison and scoring</li> <li><code>test_risk_level_determination</code> - Ensures scores map to correct risk levels</li> <li><code>test_license_score_calculation</code> - Tests license risk scoring based on license type</li> </ul> <p>These tests follow the \"Given X, the function should return Y\" pattern with clear expectations.</p>"},{"location":"project_standards/TESTING_IMPLEMENTATION/#2-regression-tests-for-known-fail-states","title":"2. Regression Tests for Known Fail States","text":"<p>These tests focus on edge cases and potential failure points:</p> <ul> <li><code>test_regression_http_error_handled_gracefully</code> - Verifies proper error handling for HTTP errors</li> <li><code>test_regression_malformed_json_response</code> - Tests handling of unexpected API responses</li> <li><code>test_regression_cache_fallback_mechanism</code> - Tests cache fallback behavior</li> <li><code>test_regression_tzinfo_handling</code> - Ensures proper handling of timezone-aware datetime objects</li> <li><code>test_regression_version_parsing_edge_cases</code> - Tests handling of non-standard version strings</li> <li><code>test_regression_weight_normalization</code> - Tests for proper handling of extreme weight values</li> </ul> <p>Each test includes descriptive comments referencing the issue being addressed.</p>"},{"location":"project_standards/TESTING_IMPLEMENTATION/#3-benchmark-tests-with-sla-enforcement","title":"3. Benchmark Tests with SLA Enforcement","text":"<p>Performance tests with specific thresholds:</p> <ul> <li><code>test_api_request_performance_sla</code> - Enforces API request timing constraints</li> <li><code>test_cache_lookup_performance_sla</code> - Ensures cache lookups meet performance requirements</li> <li><code>test_dependency_update_performance_sla</code> - Tests efficiency of dependency metadata updates</li> <li><code>test_scoring_performance_sla</code> - Enforces timing constraints for scoring operations</li> <li><code>test_project_profile_performance_sla</code> - Tests performance for large projects with many dependencies</li> </ul> <p>These tests use pytest-benchmark and include clear SLA definitions in the docstrings.</p>"},{"location":"project_standards/TESTING_IMPLEMENTATION/#4-grammatical-evolution-for-fuzzing-edge-discovery","title":"4. Grammatical Evolution for Fuzzing + Edge Discovery","text":"<p>Fuzzing tests to discover edge cases:</p> <ul> <li><code>test_fuzzing_normalize_cvss_score</code> - Tests CVSS normalization with randomized inputs</li> <li><code>test_fuzzing_severity_to_score</code> - Tests severity mapping with unexpected inputs</li> <li><code>test_fuzzing_version_difference_score</code> - Tests version comparison with various format strings</li> <li><code>test_fuzzing_staleness_score</code> - Tests date handling with edge cases</li> <li><code>test_fuzzing_risk_level_determination</code> - Tests risk level determination with boundary values</li> </ul> <p>While we simplified the full grammatical evolution implementation, these tests systematically explore the input space to find potential issues.</p>"},{"location":"project_standards/TESTING_IMPLEMENTATION/#5-structured-logs-for-agent-feedback","title":"5. Structured Logs for Agent Feedback","text":"<p>Tests focused on logging and observability:</p> <ul> <li><code>test_agent_logging_completeness</code> - Ensures comprehensive logging of operations</li> <li><code>test_structured_logging_retry_mechanism</code> - Tests detailed logging of retry mechanisms</li> <li><code>test_logging_information_completeness</code> - Tests completeness of logged information</li> <li><code>test_logging_decision_points</code> - Verifies logging of critical decision points</li> </ul> <p>These tests capture and analyze logs to ensure they provide sufficient information for monitoring and debugging.</p>"},{"location":"project_standards/TESTING_IMPLEMENTATION/#refactoring-approach","title":"Refactoring Approach","text":"<p>To make the components more testable, we:</p> <ol> <li>Used direct testing patterns to avoid complex mocking requirements</li> <li>Created simplified implementations of functions to test core logic</li> <li>Fixed timezone handling to avoid comparison issues</li> <li>Created helper classes like <code>LogCapture</code> to monitor system behavior</li> <li>Implemented proper test isolation through function-level mocking</li> </ol>"},{"location":"project_standards/TESTING_IMPLEMENTATION/#dependencies","title":"Dependencies","text":"<p>Added to support the test suite:</p> <ul> <li>pytest-benchmark for performance testing</li> <li>numpy for statistical calculations in benchmark tests</li> </ul>"},{"location":"project_standards/TESTING_IMPLEMENTATION/#running-the-tests","title":"Running the Tests","text":"<pre><code># Run all tests\npython -m pytest\n\n# Run only the comprehensive tests\npython -m pytest tests/test_comprehensive_vulnerability_aggregator.py tests/test_comprehensive_risk_scorer.py\n\n# Run benchmark tests\npython -m pytest -m benchmark\n</code></pre>"},{"location":"project_standards/TESTING_STANDARDS/","title":"Testing Standards","text":"<p>TESTING_STANDARDS.md</p>"},{"location":"project_standards/TESTING_STANDARDS/#1-hypothesis-tests-for-behavior-validation","title":"1. Hypothesis Tests for Behavior Validation","text":"<pre><code>When implementing a new feature or function, create hypothesis tests that validate expected behaviors:\n\n1. For each function, identify the core hypothesis of what it should accomplish\n2. Write tests that:\n   - Define clear expectations (\"Given X, the function should return Y\")\n   - Test both positive and negative cases\n   - Include boundary conditions\n   - Verify error handling behaviors\n3. Express these tests in the appropriate testing framework (e.g., pytest, Jest)\n4. Include descriptive test names that document the behavior being validated\n\nExample structure:\n```python\ndef test_user_authentication_valid_credentials():\n    \"\"\"HYPOTHESIS: Given valid credentials, authentication should succeed.\"\"\"\n    # Arrange\n    valid_username = \"test_user\"\n    valid_password = \"correct_password\"\n\n    # Act\n    result = authenticate_user(valid_username, valid_password)\n\n    # Assert\n    assert result.success is True\n    assert result.error_message is None\n</code></pre>"},{"location":"project_standards/TESTING_STANDARDS/#2-regression-tests-for-known-fail-states","title":"2. Regression Tests for Known Fail States","text":"<pre><code>When fixing bugs or addressing edge cases, always create regression tests:\n\n1. For each bug fix, create a test that:\n   - Documents the original issue clearly in the test description\n   - Recreates the exact conditions that caused the failure\n   - Verifies the fix works as expected\n   - Includes issue/ticket references for context\n2. Maintain a dedicated regression test suite that runs with every build\n3. Label regression tests appropriately for traceability\n4. Include timestamps and version information where relevant\n\nExample structure:\n```python\ndef test_calculation_with_zero_division_protection():\n    \"\"\"REGRESSION: Bug #1234 - Division by zero crash in calculation module.\n\n    This test ensures that when a divisor of zero is provided, the function\n    returns a default value rather than raising an exception.\n    \"\"\"\n    # Arrange\n    input_value = 10\n    divisor = 0\n    expected_result = None  # Our fix returns None instead of raising ZeroDivisionError\n\n    # Act\n    result = safe_divide(input_value, divisor)\n\n    # Assert\n    assert result == expected_result\n</code></pre>"},{"location":"project_standards/TESTING_STANDARDS/#3-benchmark-tests-with-sla-enforcement","title":"3. Benchmark Tests with SLA Enforcement","text":"<pre><code>Implement benchmark tests that enforce Service Level Agreements (SLAs):\n\n1. Define clear performance metrics for your system:\n   - Response time / latency (milliseconds)\n   - Throughput (requests per second)\n   - Resource usage (memory, CPU)\n   - Error rates\n2. Create benchmark tests that:\n   - Establish baseline performance expectations\n   - Run consistently in controlled environments\n   - Measure against defined thresholds\n   - Alert on SLA violations\n3. Include both average and percentile measurements (p95, p99)\n4. Document the testing environment and conditions\n\nExample structure:\n```python\ndef test_api_response_time_sla():\n    \"\"\"BENCHMARK: API must respond within 200ms for 95% of requests.\n\n    SLA Requirements:\n    - p95 response time: &lt; 200ms\n    - p99 response time: &lt; 500ms\n    - Error rate: &lt; 0.1%\n    \"\"\"\n    # Arrange\n    num_requests = 1000\n    endpoint = \"/api/users\"\n\n    # Act\n    response_times = []\n    errors = 0\n    for _ in range(num_requests):\n        start_time = time.time()\n        try:\n            response = client.get(endpoint)\n            if response.status_code &gt;= 400:\n                errors += 1\n        except Exception:\n            errors += 1\n        finally:\n            response_times.append((time.time() - start_time) * 1000)  # Convert to ms\n\n    # Assert\n    error_rate = errors / num_requests\n    p95 = numpy.percentile(response_times, 95)\n    p99 = numpy.percentile(response_times, 99)\n\n    assert p95 &lt; 200, f\"95th percentile response time {p95}ms exceeds SLA of 200ms\"\n    assert p99 &lt; 500, f\"99th percentile response time {p99}ms exceeds SLA of 500ms\"\n    assert error_rate &lt; 0.001, f\"Error rate {error_rate} exceeds SLA of 0.1%\"\n</code></pre>"},{"location":"project_standards/TESTING_STANDARDS/#4-grammatical-evolution-ge-for-fuzzing-edge-discovery","title":"4. Grammatical Evolution (GE) for Fuzzing + Edge Discovery","text":"<pre><code>Implement Grammatical Evolution (GE) for advanced fuzzing and edge case discovery:\n\n1. Define a grammar that represents valid inputs for your system:\n   - Create BNF (Backus-Naur Form) or similar grammar definition\n   - Include all possible input variations, formats, and structures\n   - Define mutation operations that preserve grammatical correctness\n2. Implement an evolutionary algorithm that:\n   - Generates test cases based on the grammar\n   - Evolves test cases using fitness functions\n   - Prioritizes edge cases and unexpected inputs\n   - Tracks code coverage to focus on unexplored paths\n3. Log and analyze failures to identify patterns\n4. Automatically add discovered edge cases to regression tests\n\nExample structure:\n```python\ndef test_with_grammatical_evolution():\n    \"\"\"FUZZING: Use GE to discover edge cases in the input parser.\n\n    This test uses grammatical evolution to generate various inputs\n    that conform to our API grammar but might trigger unexpected behaviors.\n    \"\"\"\n    # Define grammar for API requests\n    grammar = {\n        'start': ['&lt;request&gt;'],\n        'request': ['{\"command\": \"&lt;command&gt;\", \"params\": &lt;params&gt;}'],\n        'command': ['get', 'set', 'update', 'delete', '&lt;random_string&gt;'],\n        'params': ['&lt;simple_param&gt;', '&lt;complex_param&gt;', '&lt;nested_param&gt;', '&lt;malformed_param&gt;'],\n        # ... additional grammar rules\n    }\n\n    # Configure GE parameters\n    max_generations = 50\n    population_size = 100\n    mutation_rate = 0.1\n\n    # Run GE-based fuzzing\n    fuzzer = GrammaticalEvolutionFuzzer(grammar=grammar, \n                                      coverage_tracker=CoverageTracker(),\n                                      target_function=api_request_handler)\n\n    results = fuzzer.run(max_generations, population_size, mutation_rate)\n\n    # Analyze results\n    edge_cases = results.filter(lambda r: r.status == 'failure')\n\n    # Assert\n    assert not edge_cases.has_critical_failures(), f\"Critical failures found: {edge_cases.critical_failures}\"\n\n    # Add discovered edge cases to regression suite\n    for case in edge_cases:\n        add_to_regression_suite(case)\n</code></pre>"},{"location":"project_standards/TESTING_STANDARDS/#5-structured-logs-for-agent-feedback","title":"5. Structured Logs for Agent Feedback","text":"<pre><code>Implement structured logging for comprehensive agent feedback:\n\n1. Design a structured logging system that captures:\n   - Input/output pairs for each agent operation\n   - Decision points with considered alternatives\n   - Confidence scores for predictions or responses\n   - Time and resource utilization metrics\n   - Any deviation from expected behavior\n2. Use a consistent JSON or similar structured format\n3. Include correlation IDs to track actions across system components\n4. Implement log levels that enable filtering for different analysis needs\n5. Create analyzers that process logs to identify patterns and issues\n\nExample structure:\n```python\ndef test_agent_logging_completeness():\n    \"\"\"AGENT FEEDBACK: Verify agent produces comprehensive structured logs.\n\n    This test ensures our agent properly logs all required information\n    for debugging, monitoring, and improvement purposes.\n    \"\"\"\n    # Arrange\n    test_input = \"Process this complex request with multiple steps\"\n    expected_log_fields = [\n        \"request_id\", \"timestamp\", \"input\", \"parsed_intent\", \n        \"selected_action\", \"considered_alternatives\", \"confidence_score\", \n        \"execution_time_ms\", \"output\", \"status\"\n    ]\n\n    # Setup log capture\n    log_capture = LogCapture()\n\n    # Act\n    agent.process(test_input, log_handler=log_capture)\n\n    # Assert\n    logs = log_capture.get_logs_as_json()\n    assert len(logs) &gt; 0, \"No logs were produced\"\n\n    # Check if all required fields are present in the logs\n    for log in logs:\n        for field in expected_log_fields:\n            assert field in log, f\"Required log field '{field}' is missing\"\n\n    # Verify log sequence completeness\n    assert \"agent_started\" in [log[\"event\"] for log in logs]\n    assert \"agent_completed\" in [log[\"event\"] for log in logs]\n\n    # Verify decision points are logged with alternatives\n    decision_logs = [log for log in logs if log[\"event\"] == \"decision_point\"]\n    assert len(decision_logs) &gt; 0, \"No decision points were logged\"\n    for decision in decision_logs:\n        assert \"considered_alternatives\" in decision\n        assert len(decision[\"considered_alternatives\"]) &gt; 0\n</code></pre>"},{"location":"project_standards/TESTING_STANDARDS/#combined-meta-prompt-for-test-suite-generation","title":"Combined Meta-Prompt for Test Suite Generation","text":"<p>``` Generate a comprehensive test suite for this code that follows the Minimal Testing Manifesto:</p> <ol> <li>Create hypothesis tests that validate core behaviors:</li> <li>What are the key functions and their expected behaviors?</li> <li>What are the contracts these functions must fulfill?</li> <li> <p>What invariants must be maintained?</p> </li> <li> <p>Implement regression tests for known issues:</p> </li> <li>What edge cases have been identified?</li> <li>What bugs were previously fixed that must not reappear?</li> <li> <p>What are the failure modes we've observed?</p> </li> <li> <p>Add benchmark tests with SLA enforcement:</p> </li> <li>What performance guarantees must the code provide?</li> <li>What are the time, memory, or throughput constraints?</li> <li> <p>What are the expected error rates and reliability metrics?</p> </li> <li> <p>Use grammatical evolution for fuzzing and edge discovery:</p> </li> <li>What is the grammar of valid inputs?</li> <li>What mutations would generate interesting test cases?</li> <li> <p>How can we systematically explore the input space?</p> </li> <li> <p>Include structured logging for agent feedback:</p> </li> <li>What information must be captured at each step?</li> <li>How should decision points be documented?</li> <li>What metrics are needed for monitoring and improvement?</li> </ol> <p>For each test, include: - Clear documentation of the purpose and hypothesis - Detailed setup of test conditions - Explicit assertions with descriptive failure messages - Appropriate test categorization (unit, integration, etc.)</p> <p>The test suite should be maintainable, reliable, and provide rapid feedback on code quality and correctness.</p>"},{"location":"security/DEPENDENCY_SECURITY/","title":"Dependency Security Management","text":"<p>This document outlines our approach to managing and securing dependencies in the Dependency Risk Profiler project.</p>"},{"location":"security/DEPENDENCY_SECURITY/#security-policy","title":"Security Policy","text":"<p>We take the security of our project and its dependencies seriously. Our approach includes:</p> <ol> <li>Regular dependency auditing: We periodically scan for security vulnerabilities in our dependencies</li> <li>Prompt updates: When vulnerabilities are identified, we update affected dependencies promptly</li> <li>Minimizing dependency bloat: We carefully evaluate new dependencies before adding them</li> <li>Version pinning with minimums: We specify minimum versions rather than exact versions to allow for security patches</li> </ol>"},{"location":"security/DEPENDENCY_SECURITY/#current-security-measures","title":"Current Security Measures","text":""},{"location":"security/DEPENDENCY_SECURITY/#core-dependencies","title":"Core Dependencies","text":"<p>We maintain secure minimum versions for all dependencies:</p> Dependency Minimum Version Security Notes requests 2.32.2 Addresses CVE-2024-35195 urllib3 2.2.2 Addresses CVE-2024-37891 jinja2 3.1.5 Addresses CVE-2024-56201 certifi 2024.7.4 Addresses CVE-2024-39689 werkzeug 3.0.6 Addresses CVE-2024-49766, CVE-2024-49767 cryptography 42.0.0 Addresses CVE-2023-50782 and others pyyaml 6.0.1 Addresses potential vulnerabilities pygments 2.16.1 Addresses CVE-2023-41337 pillow 10.2.0 Addresses CVE-2023-50447, CVE-2024-35219"},{"location":"security/DEPENDENCY_SECURITY/#development-dependencies","title":"Development Dependencies","text":"<p>Development dependencies are also maintained with security in mind:</p> Dependency Minimum Version Security Notes pytest 7.4.4 Current stable version pytest-cov 4.1.0 Current stable version black 24.2.0 Current stable version isort 5.13.2 Current stable version flake8 7.0.0 Current stable version mypy 1.6.0 Current stable version responses 0.25.0 Added for HTTP mocking in tests"},{"location":"security/DEPENDENCY_SECURITY/#security-monitoring","title":"Security Monitoring","text":"<p>We use several tools to monitor for security vulnerabilities:</p> <ol> <li>GitHub Dependabot: Automatically creates PRs for vulnerabilities</li> <li>Safety: Scans Python dependencies for known vulnerabilities</li> <li>pip-audit: Additional auditing for Python packages</li> </ol>"},{"location":"security/DEPENDENCY_SECURITY/#reporting-security-issues","title":"Reporting Security Issues","text":"<p>If you discover a security vulnerability in our dependencies or in the project itself, please report it by:</p> <ol> <li>Opening a GitHub issue labeled \"security\"</li> <li>Sending an email to security@example.com (replace with actual contact)</li> </ol> <p>Please include as much information as possible about the vulnerability, including: - The affected dependency and version - Steps to reproduce - Potential impact - Suggested fixes or mitigations</p>"},{"location":"security/DEPENDENCY_SECURITY/#security-updates-schedule","title":"Security Updates Schedule","text":"<p>We review dependencies for security updates on the following schedule:</p> <ul> <li>Critical vulnerabilities: Immediate updates</li> <li>High severity: Within 7 days</li> <li>Medium/Low severity: During the next scheduled release</li> </ul>"},{"location":"security/DEPENDENCY_SECURITY/#secure-dependency-management-best-practices","title":"Secure Dependency Management Best Practices","text":"<p>When contributing to this project, please follow these best practices:</p> <ol> <li>Don't add dependencies unnecessarily: Consider if a new dependency is truly needed</li> <li>Check security history: Before adding a dependency, review its security track record</li> <li>Specify secure minimums: When adding a dependency, specify a minimum version known to be secure</li> <li>Document security implications: Comment on the security implications of dependencies in code</li> <li>Test after updates: Ensure functionality is maintained after security updates</li> </ol>"},{"location":"security/DEPENDENCY_SECURITY/#example-files-and-intentional-vulnerabilities","title":"Example Files and Intentional Vulnerabilities","text":"<p>The project contains intentionally outdated dependencies in the following directories: - <code>/examples/</code>  - <code>/dependabot_check/</code></p> <p>These files contain dependencies with known vulnerabilities for testing and demonstration purposes of the Dependency Risk Profiler tool. These intentional vulnerabilities are excluded from Dependabot alerts via the configuration in <code>.github/dependabot.yml</code>.</p> <p>DO NOT use these example dependencies in production environments.</p>"},{"location":"security/DEPENDENCY_SECURITY/#history-of-security-updates","title":"History of Security Updates","text":"<p>The project maintains a comprehensive changelog of security updates in CHANGELOG.md.</p>"},{"location":"security/DEPENDENCY_SECURITY/#recent-example-file-updates","title":"Recent Example File Updates","text":"<p>Updated in example files to address GitHub Dependabot alerts (April 16, 2025):</p>"},{"location":"security/DEPENDENCY_SECURITY/#python-dependencies-examplesrequirementstxt","title":"Python Dependencies (<code>examples/requirements.txt</code>)","text":"<ul> <li>Django: 3.2.4 \u2192 5.1.2 (Fixes various CVEs including SQL injection, denial of service)</li> <li>Flask: 2.0.1 \u2192 3.0.3 (Security and feature updates)</li> <li>Requests: 2.25.0 \u2192 2.32.2 (Fixes CVE-2024-35195)</li> <li>pytest: 6.2.5 \u2192 8.3.5 (Latest version)</li> <li>black: 21.5b2 \u2192 24.2.0 (Latest stable version)</li> <li>numpy: 1.20.0 \u2192 2.2.4 (Latest version)</li> <li>pandas: 1.2.4 \u2192 2.2.2 (Latest version)</li> </ul>"},{"location":"security/DEPENDENCY_SECURITY/#javascript-dependencies-examplespackage-lockjson","title":"JavaScript Dependencies (<code>examples/package-lock.json</code>)","text":"<ul> <li>express: 4.17.1 \u2192 4.18.2 (Latest stable version with security fixes)</li> <li>lodash: 4.17.20 \u2192 4.17.21 (Fixes prototype pollution vulnerability)</li> <li>react: 17.0.2 \u2192 18.2.0 (Latest version)</li> <li>axios: 0.21.1 \u2192 1.6.5 (Fixes various CVEs)</li> </ul>"},{"location":"security/DEPENDENCY_SECURITY/#go-dependencies-examplesgomod","title":"Go Dependencies (<code>examples/go.mod</code>)","text":"<ul> <li>Go version: 1.17 \u2192 1.22 (Latest stable version)</li> <li>gin-gonic/gin: 1.7.4 \u2192 1.9.1 (Latest stable version)</li> <li>stretchr/testify: 1.7.0 \u2192 1.9.0 (Latest version)</li> <li>sirupsen/logrus: 1.8.1 \u2192 1.9.3 (Latest version)</li> <li>gorilla/mux: 1.8.0 \u2192 1.8.1 (Latest version with security fixes)</li> <li>golang.org/x/crypto: 0.0.0-20210817164053-32db794688a5 \u2192 0.24.0 (Latest version with security fixes)</li> </ul> <p>Last updated: April 16, 2025</p>"},{"location":"security/SECURITY/","title":"Security Policy","text":""},{"location":"security/SECURITY/#supported-versions","title":"Supported Versions","text":"<p>Only the latest version of the Dependency Risk Profiler is actively maintained and supported with security updates.</p> Version Supported 0.2.x :white_check_mark: 0.1.x :x:"},{"location":"security/SECURITY/#reporting-a-vulnerability","title":"Reporting a Vulnerability","text":"<p>We take security seriously. If you discover any security issues in the Dependency Risk Profiler, please report them by following these steps:</p> <ol> <li> <p>Do not open a GitHub issue if the bug is a security vulnerability. Instead, please contact the maintainers directly via email at security@example.com.</p> </li> <li> <p>Provide a detailed report, including:</p> </li> <li>What you were doing when you discovered the vulnerability</li> <li>The potential impact of the vulnerability</li> <li> <p>Steps to reproduce the vulnerability</p> </li> <li> <p>The maintainers will acknowledge your report as soon as possible, and will provide a timeline for the fix based on the severity and complexity of the issue.</p> </li> <li> <p>Please do not disclose the issue publicly until it has been addressed and a release containing the fix has been published.</p> </li> </ol>"},{"location":"security/SECURITY/#security-considerations-for-dependency-risk-profiler","title":"Security Considerations for Dependency Risk Profiler","text":"<p>Since this tool analyzes and reports on security risks in dependencies, we are especially vigilant about security. In particular:</p> <ol> <li> <p>Data Privacy: The tool does not transmit your dependency information to external servers. All analysis is done locally.</p> </li> <li> <p>Safe Network Access: When fetching package metadata from public repositories, the tool uses only anonymous access and follows best practices for secure HTTP requests.</p> </li> <li> <p>No Execution of External Code: The tool does not execute any code from the dependencies it analyzes. It only reads and analyzes manifest files.</p> </li> <li> <p>Temporary Files: Any temporary files created during analysis are securely managed and removed when no longer needed.</p> </li> </ol>"},{"location":"security/SECURITY/#project-security-measures","title":"Project Security Measures","text":"<p>The Dependency Risk Profiler project employs several security measures for its own codebase:</p>"},{"location":"security/SECURITY/#automated-security-scanning","title":"Automated Security Scanning","text":"<ul> <li>GitHub CodeQL Analysis: Automatically scans code for potential security vulnerabilities</li> <li>Configured to exclude test directories and example code with intentional vulnerabilities</li> <li>Configuration is located in <code>.github/codeql/codeql-config.yml</code></li> <li>Runs on every push to main, pull requests to main, and weekly scheduled scans</li> <li> <p>Important Setup Note: The repository must have the default CodeQL setup disabled and advanced setup enabled in GitHub settings for the custom configuration to work properly</p> </li> <li> <p>Bandit: Python-specific security linter integrated into our CI/CD pipeline</p> </li> <li>Detects common security issues in Python code</li> <li>Run via <code>bandit -r src -c .bandit.yml</code> in our CI process</li> </ul>"},{"location":"security/SECURITY/#dependency-management","title":"Dependency Management","text":"<ul> <li>Dependabot: Automatically monitors our dependencies for vulnerabilities</li> <li>Creates pull requests when security updates are available</li> <li>Configured to exclude test directories and example code</li> <li> <p>Configuration is located in <code>.github/dependabot.yml</code></p> </li> <li> <p>Self-analysis: We regularly run the Dependency Risk Profiler against itself</p> </li> </ul>"},{"location":"security/SECURITY/#security-in-testing","title":"Security in Testing","text":"<p>Our project contains intentionally outdated dependencies and vulnerability examples in the following directories: - <code>/examples/</code>  - <code>/testing/projects/</code></p> <p>These files are used for testing and demonstration purposes of the tool's capabilities and are excluded from security scanning to avoid false positives.</p> <p>\u26a0\ufe0f WARNING: The demonstration dependencies in test and example code should not be used in production environments.</p>"},{"location":"security/SECURITY/#security-updates","title":"Security Updates","text":"<p>Security updates are announced through:</p> <ol> <li>GitHub releases</li> <li>The CHANGELOG.md file</li> <li>A note in the README.md for critical issues</li> </ol> <p>We recommend keeping your installation up to date with the latest releases.</p>"},{"location":"security/SECURITY/#recent-security-updates","title":"Recent Security Updates","text":"<ul> <li>2025-04-16 (v0.2.0): Updated dependency requirements to address the following vulnerabilities:</li> <li>requests: Updated to &gt;=2.32.2 (fixes CVE-2024-35195)</li> <li>urllib3: Updated to &gt;=2.2.2 (fixes CVE-2024-37891)</li> <li>jinja2: Updated to &gt;=3.1.5 (fixes CVE-2024-56201)</li> <li>certifi: Updated to &gt;=2024.7.4 (fixes CVE-2024-39689)</li> <li>werkzeug: Updated to &gt;=3.0.6 (fixes CVE-2024-49766, CVE-2024-49767)</li> <li>Development dependencies:<ul> <li>pytest: Updated to &gt;=7.4.0</li> <li>pytest-cov: Updated to &gt;=4.2.0</li> <li>black: Updated to &gt;=24.4.0</li> <li>isort: Updated to &gt;=5.13.2</li> <li>flake8: Updated to &gt;=7.0.0</li> <li>mypy: Updated to &gt;=1.9.0</li> </ul> </li> </ul>"},{"location":"security/SECURITY/#best-practices-when-using-this-tool","title":"Best Practices When Using This Tool","text":"<ol> <li> <p>Always run the tool with appropriate permissions - it only needs file system read access to your dependency manifests.</p> </li> <li> <p>Verify the integrity of the tool when installing it by checking the published checksums.</p> </li> <li> <p>Since the tool makes network requests to package repositories, be mindful of using it in restricted network environments.</p> </li> <li> <p>The tool reports security risks but does not automatically modify your dependencies. Always review the reported issues and make dependency updates according to your own assessment of risk.</p> </li> </ol>"}]}